{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "#import catboost as ctb\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './ccf_car'\n",
    "\n",
    "train_sales_data = pd.read_csv(path + '/train_sales_data.csv')\n",
    "train_search_data = pd.read_csv(path + '/train_search_data.csv')\n",
    "train_user_reply_data = pd.read_csv(path + '/train_user_reply_data.csv')\n",
    "\n",
    "test = pd.read_csv(path + '/evaluation_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_sales_data, test], ignore_index=True)\n",
    "data = data.merge(train_search_data, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user_reply_data, 'left', on=['model', 'regYear', 'regMonth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "del data['salesVolume'], data['forecastVolum']\n",
    "data['bodyType'] = data['model'].map(train_sales_data.drop_duplicates('model').set_index('model')['bodyType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adcode</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>province</th>\n",
       "      <th>regMonth</th>\n",
       "      <th>regYear</th>\n",
       "      <th>popularity</th>\n",
       "      <th>carCommentVolum</th>\n",
       "      <th>newsReplyVolum</th>\n",
       "      <th>label</th>\n",
       "      <th>mt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>上海</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>云南</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>内蒙古</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>北京</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>四川</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>3562.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adcode  bodyType  id  model province  regMonth  regYear  popularity  \\\n",
       "0  310000         0   0      0       上海         1     2016      1479.0   \n",
       "1  530000         0   0      0       云南         1     2016      1594.0   \n",
       "2  150000         0   0      0      内蒙古         1     2016      1479.0   \n",
       "3  110000         0   0      0       北京         1     2016      2370.0   \n",
       "4  510000         0   0      0       四川         1     2016      3562.0   \n",
       "\n",
       "   carCommentVolum  newsReplyVolum  label  mt  \n",
       "0             11.0           106.0  292.0   1  \n",
       "1             11.0           106.0  466.0   1  \n",
       "2             11.0           106.0  257.0   1  \n",
       "3             11.0           106.0  408.0   1  \n",
       "4             11.0           106.0  610.0   1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_feat = []\n",
    "\n",
    "data['model_adcode'] = data['adcode'] + data['model']\n",
    "data['model_adcode_mt'] = data['model_adcode'] * 100 + data['mt']\n",
    "for i in [11]:\n",
    "    i = i + 1\n",
    "    shift_feat.append('shift_model_adcode_mt_label_{0}'.format(i))\n",
    "    data['model_adcode_mt_{0}'.format(i)] = data['model_adcode_mt'] + i\n",
    "    data_last = data[~data.label.isnull()].set_index('model_adcode_mt_{0}'.format(i))\n",
    "    data['shift_model_adcode_mt_label_{0}'.format(i)] = data['model_adcode_mt'].map(data_last['label'])\n",
    "\n",
    "num_feat = ['regYear'] + shift_feat\n",
    "cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = num_feat + cate_feat\n",
    "\n",
    "# data['n_label'] = data['label'] / data.groupby('model')['label'].transform('mean')\n",
    "train_idx = (data['mt'] <= 20)\n",
    "\n",
    "valid_idx = (data['mt'].between(21, 24))\n",
    "\n",
    "test_idx = (data['mt'] > 24)\n",
    "\n",
    "data['model_weight'] = data.groupby('model')['label'].transform('mean')\n",
    "data['n_label'] = data['label'] / data['model_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data[train_idx][features]\n",
    "train_y = data[train_idx]['n_label']\n",
    "\n",
    "valid_x = data[valid_idx][features]\n",
    "valid_y = data[valid_idx]['n_label']\n",
    "\n",
    "# test_x = data[test_idx][features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's l2: 0.289116\n",
      "[200]\tvalid_0's l2: 0.247219\n",
      "[300]\tvalid_0's l2: 0.238665\n",
      "[400]\tvalid_0's l2: 0.239144\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid_0's l2: 0.237607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,\n",
       "              importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "              min_child_samples=5, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=5000, n_jobs=-1, num_leaves=32, objective='mse',\n",
       "              random_state=372, reg_alpha=1, reg_lambda=0.1, silent=True,\n",
       "              subsample=0.8, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMRegressor(\n",
    "    num_leaves=32, reg_alpha=1, reg_lambda=0.1, objective='mse',\n",
    "    max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=np.random.randint(1000),\n",
    "    n_estimators=5000, subsample=0.8, colsample_bytree=0.8,\n",
    ")\n",
    "\n",
    "lgb_model.fit(train_x, train_y, eval_set=[\n",
    "    (valid_x, valid_y),\n",
    "], categorical_feature=cate_feat, early_stopping_rounds=100, verbose=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data[pred] = data[pred].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred: list,\n",
    "        label: [list, 'mean'],\n",
    "\n",
    "    }).reset_index()\n",
    "\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print('scoring:')\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def xgb_Regressor(train_x, train_y, val_x, val_y):\n",
    "    '''\n",
    "    xgb_model = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, num_leaves=20,\n",
    "                             n_estimators=5000,reg_alpha=1, reg_lambda=0.1,\n",
    "                             subsample=0.8, silent=1,min_child_samples=5,\n",
    "                             random_state =np.random.randint(1000), nthread = -1)\n",
    "    \n",
    "    for cate in cate_feat:\n",
    "        train_x[cate] = LabelEncoder().fit_transform(train_x[cate])\n",
    "        val_x[cate] = LabelEncoder().fit_transform(val_x[cate])\n",
    "    xgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y),\n",
    "           ], early_stopping_rounds=100, verbose=100)\n",
    "    data['xgb_pred'] = xgb_model.predict(data[features]) * data['model_weight']\n",
    "    best_score = score(data[valid_idx],pred='xgb_pred')\n",
    "    #lgb_model.n_estimators = 666\n",
    "    return xgb_model\n",
    "    '''\n",
    "    '''\n",
    "    param = {\n",
    "        'max_depth' : 6,\n",
    "        'eta' : 0.02,\n",
    "        'objective' : 'reg:linear',\n",
    "        'silent': 0,\n",
    "        #     'nthread': 4,\n",
    "        #     'booster': 'gbtree'\n",
    "    }\n",
    "    num_round = 130\n",
    "    #num_round = 8000 # v0.2 best 129  # 8000\n",
    "    dtrain = xgb.DMatrix(train_x, label=train_y, missing=np.nan) \n",
    "    # dtest = xgb.DMatrix(df_test)\n",
    "    dtest = xgb.DMatrix(val_x, label=val_y.values, missing=np.nan) \n",
    "    eval_set = [(dtrain, 'train'), (dtest, 'validation')]\n",
    "    xgb_model = xgb.train(param, dtrain, num_round, verbose_eval=True, early_stopping_rounds=20, evals=eval_set)#early stop 200\n",
    "    '''\n",
    "    xgb_model = xgb.XGBRegressor(max_depth=6,\n",
    "        eta=0.02,\n",
    "        objective='reg:linear',\n",
    "        silent=0)\n",
    "    \n",
    "    #for cate in cate_feat:\n",
    "    #    train_x[cate] = LabelEncoder().fit_transform(train_x[cate])\n",
    "    xgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y),\n",
    "            ], early_stopping_rounds=100, verbose=100)\n",
    "    #df=xgb.DMatrix(data[features],label=data['n_label'].values)\n",
    "    data['xgb_pred'] = xgb_model.predict(data[features]) * data['model_weight']\n",
    "    best_score = score(data[valid_idx],pred='xgb_pred')\n",
    "    #lgb_model.n_estimators = 666\n",
    "    return xgb_model\n",
    "    \n",
    "\n",
    "def lgb_Regressor(train_x, train_y, valid_x, valid_y):\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        num_leaves=32, reg_alpha=1, reg_lambda=0.1, objective='mse',\n",
    "        max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=np.random.randint(1000),\n",
    "        n_estimators=5000, subsample=0.8, colsample_bytree=0.8,\n",
    "    )\n",
    "    \n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(train_x, train_y), (valid_x, valid_y),\n",
    "            ], categorical_feature=cate_feat, early_stopping_rounds=100, verbose=100)\n",
    "    \n",
    "    data['lgb_pred'] = lgb_model.predict(data[features]) * data['model_weight']\n",
    "    best_score = score(data[valid_idx],pred='lgb_pred')\n",
    "    lgb_model.n_estimators = 666\n",
    "    return lgb_model\n",
    "\n",
    "def base_model():\n",
    "    ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "    lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "\n",
    "    return ENet,lasso\n",
    "\n",
    "def gboost_Regressor(train_x, train_y, val_x, val_y, train_X, y):\n",
    "    gb_model = GradientBoostingRegressor(n_estimators=3600, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=20, min_samples_split=20, \n",
    "                    loss='huber', random_state =5)\n",
    "    gb_model.fit(train_x, train_y)\n",
    "    pred_val = gb_model.predict(val_x)\n",
    "    score = rmsle(val_y, pred_val)\n",
    "    gb_model.fit(train_X, y)\n",
    "    \n",
    "    return gb_model, score, pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBRegressor开始训练...\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 0.162392\tvalid_1's l2: 0.289954\n",
      "[200]\ttraining's l2: 0.102711\tvalid_1's l2: 0.26303\n",
      "[300]\ttraining's l2: 0.0817219\tvalid_1's l2: 0.258462\n",
      "[400]\ttraining's l2: 0.0683372\tvalid_1's l2: 0.254229\n",
      "[500]\ttraining's l2: 0.0590822\tvalid_1's l2: 0.254438\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttraining's l2: 0.0610146\tvalid_1's l2: 0.253616\n",
      "scoring:\n",
      "0.5953230848000274\n",
      "<function score at 0x00000242DE912510>\n"
     ]
    }
   ],
   "source": [
    "print(\"LGBRegressor开始训练...\")\n",
    "lgb_reg= lgb_Regressor(train_x, train_y, valid_x, valid_y)\n",
    "print(score)\n",
    "lgb_pred = lgb_reg.predict(data[test_idx][features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOSTRegressor开始训练...\n",
      "[16:59:46] WARNING: C:/dev/libs/xgboost/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:0.959292\tvalidation_1-rmse:1.14599\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[99]\tvalidation_0-rmse:0.418656\tvalidation_1-rmse:0.519423\n",
      "scoring:\n",
      "0.5586724872501776\n",
      "<function score at 0x00000242DE912510>\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBOOSTRegressor开始训练...\")\n",
    "xgb_reg = xgb_Regressor(train_x, train_y, valid_x, valid_y)\n",
    "print(score)\n",
    "xgb_pred = xgb_reg.predict(data[test_idx][features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pred_label'] = lgb_model.predict(data[features]) * data['model_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_lgb_rst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scoring:\n",
      "0.243033927745538\n"
     ]
    }
   ],
   "source": [
    "best_score = score(data[valid_idx])\n",
    "lgb_model.n_estimators = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model.fit(data[~test_idx][features], data[~test_idx]['n_label'], categorical_feature=cate_feat)\n",
    "data['forecastVolum'] = lgb_model.predict(data[features]) * data['model_weight']\n",
    "sub = data[test_idx][['id']]\n",
    "sub['forecastVolum'] = data[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "sub.to_csv(path + 'lgb_base_0_46.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
