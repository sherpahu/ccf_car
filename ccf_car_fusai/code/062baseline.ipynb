{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.0369543\tvalid_1's l2: 0.0515822\n",
      "[200]\ttraining's l2: 0.0242917\tvalid_1's l2: 0.0519154\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's l2: 0.032381\tvalid_1's l2: 0.0509363\n",
      "lgb_model_1 has saved\n",
      "0.7549634677045867\n",
      "valid mean: 513.8885700431957\n",
      "true  mean: 559.0532150776053\n",
      "test  mean: 579.7052120595454\n",
      "(1804, 2)\n",
      "35 35\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.037655\tvalid_1's l2: 0.0804799\n",
      "[200]\ttraining's l2: 0.025322\tvalid_1's l2: 0.0761655\n",
      "[300]\ttraining's l2: 0.0200272\tvalid_1's l2: 0.0743928\n",
      "[400]\ttraining's l2: 0.0165897\tvalid_1's l2: 0.0733366\n",
      "[500]\ttraining's l2: 0.0141101\tvalid_1's l2: 0.0730922\n",
      "[600]\ttraining's l2: 0.0122509\tvalid_1's l2: 0.0725418\n",
      "[700]\ttraining's l2: 0.0107184\tvalid_1's l2: 0.0726725\n",
      "Early stopping, best iteration is:\n",
      "[607]\ttraining's l2: 0.0121375\tvalid_1's l2: 0.0725008\n",
      "lgb_model_2 has saved\n",
      "0.740789861156999\n",
      "valid mean: 520.0024716611991\n",
      "true  mean: 531.319290465632\n",
      "test  mean: 437.7366030181242\n",
      "(1804, 2)\n",
      "35 35\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.0393617\tvalid_1's l2: 0.0573812\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's l2: 0.0555747\tvalid_1's l2: 0.0541455\n",
      "lgb_model_3 has saved\n",
      "0.7349148243561534\n",
      "valid mean: 527.1102715515472\n",
      "true  mean: 577.2344789356985\n",
      "test  mean: 529.5752525608386\n",
      "(1804, 2)\n",
      "35 35\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 0.0392653\tvalid_1's l2: 0.129062\n",
      "[200]\ttraining's l2: 0.0269264\tvalid_1's l2: 0.12687\n",
      "Early stopping, best iteration is:\n",
      "[179]\ttraining's l2: 0.0284775\tvalid_1's l2: 0.126369\n",
      "lgb_model_4 has saved\n",
      "0.6191950276038576\n",
      "valid mean: 579.7109531305998\n",
      "true  mean: 769.5532150776053\n",
      "test  mean: 489.5579405695364\n",
      "(1804, 2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "from sklearn.externals import joblib\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "train_sales  = pd.read_csv('../ccf_car/train_sales_data.csv')\n",
    "train_search = pd.read_csv('../ccf_car/train_search_data.csv')\n",
    "train_user   = pd.read_csv('../ccf_car/train_user_reply_data.csv')\n",
    "evaluation_public = pd.read_csv('../ccf_car/evaluation_public.csv')\n",
    "submit_example    = pd.read_csv('../ccf_car/submit_example.csv')\n",
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "# data=pd.concat([data, k_mean_data], axis=1)\n",
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "#LabelEncoder\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "def get_stat_feature(df_,): \n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    stat_feat_2=[]\n",
    "    stat_feat_3 = []\n",
    "    stat_feat_4 = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "    for col in ['label']:\n",
    "        # 历史销量数据特征\n",
    "        for i in [1,2,3,4,5,6,8,9,10,11,12,13,14,15,16]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            stat_feat_2.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i#新加一列值，等于车型*省*时间+i，寻求i个月前的值，将model_adcode_mt_作为索引\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])#后者索引是31000002开始，前者少i，取前面的匹配后面索引成功，就取值\n",
    "    for col in ['popularity']:\n",
    "        # 历史销量数据特征\n",
    "        for i in [1,2,3,10,11,12]:#popularity只取一部分\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            stat_feat_2.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i#新加一列值，等于车型*省*时间+i，寻求i个月前的值，将model_adcode_mt_作为索引\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])#后者索引是31000002开始，前者少i，取前面的匹配后面索引成功，就取值\n",
    "    df[\"increase16_4\"]=(df[\"shift_model_adcode_mt_label_16\"]-df[\"shift_model_adcode_mt_label_4\"])/df[\"shift_model_adcode_mt_label_16\"]#同比一年前的增长\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_12.agg({\"mean_province\":\"mean\",\n",
    "                                                                          \"min_province\":\"min\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_15.agg({\"mean_province_15\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_3.agg({\"mean_province_3\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_16.agg({\"mean_province_16\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_4.agg({\"mean_province_4\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "\t#另一种统计方式\n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_15.agg({\"mean_Month_15\":\"mean\"}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\") \n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_3.agg({\"mean_Month_3\":\"mean\"}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\") \n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_16.agg({\"mean_Month_16\":\"mean\"}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\") \n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_4.agg({\"mean_Month_4\":\"mean\"}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\") \n",
    "    #基于统计特征的increase，强特\n",
    "    df[\"increase_mean_province_16_4\"]=(df[\"mean_province_16\"]-df[\"mean_province_4\"])/df[\"mean_province_16\"]\n",
    "    df[\"increase_mean_province_15_3\"]=(df[\"mean_province_15\"]-df[\"mean_province_3\"])/df[\"mean_province_15\"]\n",
    "    df[\"increase_mean_Month_15_3\"]=(df[\"mean_Month_15\"]-df[\"mean_Month_3\"])/df[\"mean_Month_15\"]\n",
    "    df[\"increase_mean_Month_16_4\"]=(df[\"mean_Month_16\"]-df[\"mean_Month_4\"])/df[\"mean_Month_16\"]\n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_12.agg({\"mean_Month\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    " \t#几个月sum\n",
    "    df[\"sum_1\"]=df[\"shift_model_adcode_mt_label_11\"].values+df[\"shift_model_adcode_mt_label_12\"].values+df[\"shift_model_adcode_mt_label_1\"].values+df[\"shift_model_adcode_mt_label_2\"].values\n",
    "    df[\"sum_2\"]=df[\"shift_model_adcode_mt_label_12\"].values+df[\"shift_model_adcode_mt_label_1\"].values\n",
    "    df[\"sum_3\"]=df[\"shift_model_adcode_mt_label_3\"].values+df[\"shift_model_adcode_mt_label_2\"].values+df[\"shift_model_adcode_mt_label_1\"].values\n",
    "    stat_feat_4 = [\"mean_province\",\"min_province\",\"mean_Month\",\"sum_1\",\"sum_2\",\"sum_3\",\"increase16_4\",\n",
    "                   \"increase_mean_province_15_3\",\"increase_mean_Month_15_3\",\"increase_mean_province_16_4\",\"increase_mean_Month_16_4\"]#所有统计特征\n",
    "    stat_feat.remove(\"shift_model_adcode_mt_label_15\")#删掉两个特征\n",
    "    stat_feat.remove(\"shift_model_adcode_mt_label_16\")\n",
    "    return df,stat_feat+stat_feat_3+stat_feat_4\n",
    "\t#下面基本和鱼佬一样\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'. format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(mse(raw[0], raw[1]) ** 0.5 / raw[2] )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb',i=0):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=10, random_state=2019,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,num_threads= -1,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "        joblib.dump(model, \"lgbm_\"+str(i)+\".m\")\n",
    "        print(\"lgb_model_%d has saved\"%i)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "        joblib.dump(model, \"xgbm_\"+str(i)+\".m\")\n",
    "        print(\"xgb_model_%d has saved\"%i)\n",
    "    return model\n",
    "def get_train_model(df_, m, m_type='lgb',i=0):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分m=25,26,27,28,\n",
    "    st = 13#start time \n",
    "    all_idx   = (df['mt'].between(st , m-1))#原版\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['n_label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['n_label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type,i)  \n",
    "    # offline\n",
    "    df['pred_label'] = np.expm1(model.predict(df[features]))\n",
    "    best_score = score(df[valid_idx]) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['n_label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['n_label'])\n",
    "    df['forecastVolum'] = np.expm1(model.predict(df[features]))\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int) \n",
    "    print(sub.shape)\n",
    "    return sub,df[valid_idx]['pred_label']\n",
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    data['n_label'] = np.log1p(data['label'])\n",
    "    data_df, stat_feat = get_stat_feature(data)#每次都要更新下特征\n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth',]#,'k_mean_1','k_mean'\n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str)) \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type,month-24)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "sub[['id','forecastVolum']].round().astype(int).to_csv('../rst/062_baseline_B_res.csv', index=False)\n",
    "#结果基于规则纠正\n",
    "my_data=pd.read_csv('../rst/062_baseline_B_res.csv')\n",
    "my_data[\"forecastVolum\"]=my_data[\"forecastVolum\"]*0.79-5\n",
    "my_data[\"forecastVolum\"]=(my_data[\"forecastVolum\"]).astype(int)\n",
    "my_data.loc[my_data[my_data[\"forecastVolum\"] < 4].index,\"forecastVolum\"]=4\n",
    "my_data.loc[my_data[my_data[\"forecastVolum\"] >9000].index,\"forecastVolum\"]=9000\n",
    "my_data.to_csv('../rst/062_baseline_submit.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n",
      "[0]\tvalidation_0-rmse:5.14454\tvalidation_1-rmse:5.33674\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:0.445216\tvalidation_1-rmse:0.482611\n",
      "[200]\tvalidation_0-rmse:0.209493\tvalidation_1-rmse:0.241494\n",
      "[300]\tvalidation_0-rmse:0.184536\tvalidation_1-rmse:0.24108\n",
      "[400]\tvalidation_0-rmse:0.168294\tvalidation_1-rmse:0.241415\n",
      "Stopping. Best iteration:\n",
      "[329]\tvalidation_0-rmse:0.179106\tvalidation_1-rmse:0.240482\n",
      "\n",
      "xgb_model_1 has saved\n",
      "0.7764395574677637\n",
      "valid mean: 538.433349609375\n",
      "true  mean: 559.0532150776053\n",
      "test  mean: 588.7451782226562\n",
      "(1804, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n",
      "[0]\tvalidation_0-rmse:5.16624\tvalidation_1-rmse:5.27017\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:0.444944\tvalidation_1-rmse:0.517101\n",
      "[200]\tvalidation_0-rmse:0.209191\tvalidation_1-rmse:0.294824\n",
      "Stopping. Best iteration:\n",
      "[192]\tvalidation_0-rmse:0.211373\tvalidation_1-rmse:0.293526\n",
      "\n",
      "xgb_model_2 has saved\n",
      "0.7138411280544099\n",
      "valid mean: 461.02960205078125\n",
      "true  mean: 531.319290465632\n",
      "test  mean: 508.56231689453125\n",
      "(1804, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 32.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n",
      "[0]\tvalidation_0-rmse:5.17673\tvalidation_1-rmse:5.36037\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:0.446179\tvalidation_1-rmse:0.492762\n",
      "[200]\tvalidation_0-rmse:0.2115\tvalidation_1-rmse:0.243128\n",
      "[300]\tvalidation_0-rmse:0.189822\tvalidation_1-rmse:0.243209\n",
      "Stopping. Best iteration:\n",
      "[226]\tvalidation_0-rmse:0.20408\tvalidation_1-rmse:0.242202\n",
      "\n",
      "xgb_model_3 has saved\n",
      "0.7555849232794047\n",
      "valid mean: 535.4835815429688\n",
      "true  mean: 577.2344789356985\n",
      "test  mean: 536.6865844726562\n",
      "(1804, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 33.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n",
      "[0]\tvalidation_0-rmse:5.19369\tvalidation_1-rmse:5.60435\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:0.445998\tvalidation_1-rmse:0.677124\n",
      "[200]\tvalidation_0-rmse:0.210522\tvalidation_1-rmse:0.386405\n",
      "[300]\tvalidation_0-rmse:0.190123\tvalidation_1-rmse:0.385717\n",
      "Stopping. Best iteration:\n",
      "[262]\tvalidation_0-rmse:0.197307\tvalidation_1-rmse:0.384384\n",
      "\n",
      "xgb_model_4 has saved\n",
      "0.6245653937703055\n",
      "valid mean: 577.8416748046875\n",
      "true  mean: 769.5532150776053\n",
      "test  mean: 506.5686340332031\n",
      "(1804, 2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "from sklearn.externals import joblib\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "train_sales  = pd.read_csv('../ccf_car/train_sales_data.csv')\n",
    "train_search = pd.read_csv('../ccf_car/train_search_data.csv')\n",
    "train_user   = pd.read_csv('../ccf_car/train_user_reply_data.csv')\n",
    "evaluation_public = pd.read_csv('../ccf_car/evaluation_public.csv')\n",
    "submit_example    = pd.read_csv('../ccf_car/submit_example.csv')\n",
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "# data=pd.concat([data, k_mean_data], axis=1)\n",
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "#LabelEncoder\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "def get_stat_feature(df_,): \n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    stat_feat_2=[]\n",
    "    stat_feat_3 = []\n",
    "    stat_feat_4 = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "    for col in ['label']:\n",
    "        # 历史销量数据特征\n",
    "        for i in [1,2,3,4,5,6,8,9,10,11,12,13,14,15,16]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            stat_feat_2.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i#新加一列值，等于车型*省*时间+i，寻求i个月前的值，将model_adcode_mt_作为索引\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])#后者索引是31000002开始，前者少i，取前面的匹配后面索引成功，就取值\n",
    "    for col in ['popularity']:\n",
    "        # 历史销量数据特征\n",
    "        for i in [1,2,3,10,11,12]:#popularity只取一部分\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            stat_feat_2.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i#新加一列值，等于车型*省*时间+i，寻求i个月前的值，将model_adcode_mt_作为索引\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])#后者索引是31000002开始，前者少i，取前面的匹配后面索引成功，就取值\n",
    "    df[\"increase16_4\"]=(df[\"shift_model_adcode_mt_label_16\"]-df[\"shift_model_adcode_mt_label_4\"])/df[\"shift_model_adcode_mt_label_16\"]#同比一年前的增长\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_12.agg({\"mean_province\":\"mean\",\n",
    "                                                                          \"min_province\":\"min\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_15.agg({\"mean_province_15\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_3.agg({\"mean_province_3\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_16.agg({\"mean_province_16\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "    mean=pd.DataFrame(df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_4.agg({\"mean_province_4\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"model\",\"mt\"],how=\"left\")\n",
    "\t#另一种统计方式\n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_15.agg({\"mean_Month_15\":\"mean\"}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\") \n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_3.agg({\"mean_Month_3\":\"mean\"}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\") \n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_16.agg({\"mean_Month_16\":\"mean\"}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\") \n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_4.agg({\"mean_Month_4\":\"mean\"}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\") \n",
    "    #基于统计特征的increase，强特\n",
    "    df[\"increase_mean_province_16_4\"]=(df[\"mean_province_16\"]-df[\"mean_province_4\"])/df[\"mean_province_16\"]\n",
    "    df[\"increase_mean_province_15_3\"]=(df[\"mean_province_15\"]-df[\"mean_province_3\"])/df[\"mean_province_15\"]\n",
    "    df[\"increase_mean_Month_15_3\"]=(df[\"mean_Month_15\"]-df[\"mean_Month_3\"])/df[\"mean_Month_15\"]\n",
    "    df[\"increase_mean_Month_16_4\"]=(df[\"mean_Month_16\"]-df[\"mean_Month_4\"])/df[\"mean_Month_16\"]\n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_12.agg({\"mean_Month\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    " \t#几个月sum\n",
    "    df[\"sum_1\"]=df[\"shift_model_adcode_mt_label_11\"].values+df[\"shift_model_adcode_mt_label_12\"].values+df[\"shift_model_adcode_mt_label_1\"].values+df[\"shift_model_adcode_mt_label_2\"].values\n",
    "    df[\"sum_2\"]=df[\"shift_model_adcode_mt_label_12\"].values+df[\"shift_model_adcode_mt_label_1\"].values\n",
    "    df[\"sum_3\"]=df[\"shift_model_adcode_mt_label_3\"].values+df[\"shift_model_adcode_mt_label_2\"].values+df[\"shift_model_adcode_mt_label_1\"].values\n",
    "    stat_feat_4 = [\"mean_province\",\"min_province\",\"mean_Month\",\"sum_1\",\"sum_2\",\"sum_3\",\"increase16_4\",\n",
    "                   \"increase_mean_province_15_3\",\"increase_mean_Month_15_3\",\"increase_mean_province_16_4\",\"increase_mean_Month_16_4\"]#所有统计特征\n",
    "    stat_feat.remove(\"shift_model_adcode_mt_label_15\")#删掉两个特征\n",
    "    stat_feat.remove(\"shift_model_adcode_mt_label_16\")\n",
    "    return df,stat_feat+stat_feat_3+stat_feat_4\n",
    "\t#下面基本和鱼佬一样\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'. format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(mse(raw[0], raw[1]) ** 0.5 / raw[2] )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb',i=0):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=10, random_state=2019,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,num_threads= -1,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "        joblib.dump(model, \"lgbm_\"+str(i)+\".m\")\n",
    "        print(\"lgb_model_%d has saved\"%i)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "        joblib.dump(model, \"xgbm_\"+str(i)+\".m\")\n",
    "        print(\"xgb_model_%d has saved\"%i)\n",
    "    return model\n",
    "def get_train_model(df_, m, m_type='lgb',i=0):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分m=25,26,27,28,\n",
    "    st = 13#start time \n",
    "    all_idx   = (df['mt'].between(st , m-1))#原版\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['n_label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['n_label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type,i)  \n",
    "    # offline\n",
    "    df['pred_label'] = np.expm1(model.predict(df[features]))\n",
    "    best_score = score(df[valid_idx]) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['n_label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['n_label'])\n",
    "    df['forecastVolum'] = np.expm1(model.predict(df[features]))\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int) \n",
    "    print(sub.shape)\n",
    "    return sub,df[valid_idx]['pred_label']\n",
    "for month in [25,26,27,28]: \n",
    "    m_type = 'xgb' \n",
    "    data['n_label'] = np.log1p(data['label'])\n",
    "    data_df, stat_feat = get_stat_feature(data)#每次都要更新下特征\n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth',]#,'k_mean_1','k_mean'\n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str)) \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type,month-24)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "sub[['id','forecastVolum']].round().astype(int).to_csv('../rst/062_baseline_B_res_xgb.csv', index=False)\n",
    "#结果基于规则纠正\n",
    "my_data=pd.read_csv('../rst/062_baseline_B_res_xgb.csv')\n",
    "my_data[\"forecastVolum\"]=my_data[\"forecastVolum\"]*0.79-5\n",
    "my_data[\"forecastVolum\"]=(my_data[\"forecastVolum\"]).astype(int)\n",
    "my_data.loc[my_data[my_data[\"forecastVolum\"] < 4].index,\"forecastVolum\"]=4\n",
    "my_data.loc[my_data[my_data[\"forecastVolum\"] >9000].index,\"forecastVolum\"]=9000\n",
    "my_data.to_csv('../rst/062_baseline_xgb.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
