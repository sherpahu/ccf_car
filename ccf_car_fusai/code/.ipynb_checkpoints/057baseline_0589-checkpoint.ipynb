{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = 'E:\\\\competition\\\\ccf_car\\\\gongzhen'\n",
    "path = ''\n",
    "train_sales= pd.read_csv(path+'../ccf_car/train_sales_data.csv')#, engine='python')\n",
    "train_search_data = pd.read_csv(path+'../ccf_car/train_search_data.csv')#, engine='python')\n",
    "train_user_reply_data = pd.read_csv(path+'../ccf_car/train_user_reply_data.csv')#, engine='python')\n",
    "test = pd.read_csv(path+'../ccf_car/evaluation_public.csv')#, engine='python')\n",
    "train_sales.drop(['province'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sales\\train_search_data\\train_user_reply_data  拼接\n",
    "data = pd.merge(train_sales, train_search_data, 'left', on=['adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = pd.merge(data, train_user_reply_data, 'left', on=['model', 'regYear', 'regMonth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.58973169000\n",
    "def quantile_clip(group):\n",
    "    #group.plot()\n",
    "    group[group < group.quantile(.05)] = group.quantile(.05)\n",
    "    group[group > group.quantile(.9)] = group.quantile(.9)\n",
    "    #group.plot()\n",
    "    #plt.show()\n",
    "    return group\n",
    "data['salesVolume'] = data.groupby(['adcode', 'model'])['salesVolume'].transform(quantile_clip)\n",
    "#data['popularity'] = data.groupby(['adcode', 'model'])['popularity'].transform(quantile_clip)\n",
    "#data['carCommentVolum'] = data.groupby(['adcode', 'model'])['popularity'].transform(quantile_clip)\n",
    "#data['newsReplyVolum'] = data.groupby(['adcode', 'model'])['popularity'].transform(quantile_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计销量\n",
    "data['bt_ry_mean'] = data.groupby(['bodyType','regYear'])['salesVolume'].transform('mean')\n",
    "data['ad_ry_mean'] = data.groupby(['adcode','regYear'])['salesVolume'].transform('mean')\n",
    "data['md_ry_mean'] = data.groupby(['model','regYear'])['salesVolume'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "一、lgb预测\n",
    "'''\n",
    "# 测试集并入\n",
    "data = pd.concat([data, test], ignore_index=True)\n",
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "del data['salesVolume'], data['forecastVolum']\n",
    "# 填补测试集的车身类型\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "# 编码 bodyType、model\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "# 距离2016年的时间间隔，月数\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    " \n",
    "shift_feat = []\n",
    "data['model_adcode'] = data['adcode'] + data['model']\n",
    "data['model_adcode_mt'] = data['model_adcode'] * 100 + data['mt']\n",
    "\n",
    "# 填充测试集特征值\n",
    "# 填充测试集特征值\n",
    "for col in ['carCommentVolum','newsReplyVolum','popularity','bt_ry_mean','ad_ry_mean', 'md_ry_mean']:\n",
    "    #1月\n",
    "    m1_12 = data.loc[(data.regYear==2017)&(data.regMonth==1) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==12), col].values\n",
    "    m1_11 = data.loc[(data.regYear==2017)&(data.regMonth==1) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==11), col].values\n",
    "    m1_10 = data.loc[(data.regYear==2017)&(data.regMonth==1) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==10), col].values\n",
    "    m1_09 = data.loc[(data.regYear==2017)&(data.regMonth==1) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==9) , col].values\n",
    "    m1_08 = data.loc[(data.regYear==2017)&(data.regMonth==1) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==8) , col].values\n",
    "    m1_07 = data.loc[(data.regYear==2017)&(data.regMonth==1) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==7) , col].values\n",
    "    m1_06 = data.loc[(data.regYear==2017)&(data.regMonth==1) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==6) , col].values\n",
    "\n",
    "    m1_12_volum = data.loc[(data.regYear==2017)&(data.regMonth==12), col].values * m1_12\n",
    "    m1_11_volum = data.loc[(data.regYear==2017)&(data.regMonth==11), col].values * m1_11\n",
    "    m1_10_volum = data.loc[(data.regYear==2017)&(data.regMonth==10), col].values * m1_10\n",
    "    m1_09_volum = data.loc[(data.regYear==2017)&(data.regMonth==9) , col].values * m1_09\n",
    "    m1_08_volum = data.loc[(data.regYear==2017)&(data.regMonth==8) , col].values * m1_08\n",
    "    m1_07_volum = data.loc[(data.regYear==2017)&(data.regMonth==7) , col].values * m1_07\n",
    "    m1_06_volum = data.loc[(data.regYear==2017)&(data.regMonth==6) , col].values * m1_06\n",
    "\n",
    "    data.loc[(data.regMonth==1)&(data.regYear==2018), col] = m1_12_volum/2 + m1_11_volum/4 + m1_10_volum/8 + m1_09_volum/16 + m1_08_volum/32 + m1_07_volum/64 + m1_06_volum/64\n",
    "\n",
    "    #2月\n",
    "    m2_01 = data.loc[(data.regYear==2017)&(data.regMonth==2) , col].values / data.loc[(data.regYear==2017)&(data.regMonth==1 ) , col].values\n",
    "    m2_12 = data.loc[(data.regYear==2017)&(data.regMonth==2) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==12) , col].values\n",
    "    m2_11 = data.loc[(data.regYear==2017)&(data.regMonth==2) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==11) , col].values\n",
    "    m2_10 = data.loc[(data.regYear==2017)&(data.regMonth==2) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==10) , col].values\n",
    "    m2_09 = data.loc[(data.regYear==2017)&(data.regMonth==2) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==9 ) , col].values\n",
    "    m2_08 = data.loc[(data.regYear==2017)&(data.regMonth==2) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==8 ) , col].values\n",
    "    m2_07 = data.loc[(data.regYear==2017)&(data.regMonth==2) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==7 ) , col].values\n",
    "\n",
    "    m2_01_volum = data.loc[(data.regYear==2018)&(data.regMonth==1 ), col].values * m2_01\n",
    "    m2_12_volum = data.loc[(data.regYear==2017)&(data.regMonth==12), col].values * m2_12\n",
    "    m2_11_volum = data.loc[(data.regYear==2017)&(data.regMonth==11), col].values * m2_11\n",
    "    m2_10_volum = data.loc[(data.regYear==2017)&(data.regMonth==10), col].values * m2_10\n",
    "    m2_09_volum = data.loc[(data.regYear==2017)&(data.regMonth==9) , col].values * m2_09\n",
    "    m2_08_volum = data.loc[(data.regYear==2017)&(data.regMonth==8) , col].values * m2_08\n",
    "    m2_07_volum = data.loc[(data.regYear==2017)&(data.regMonth==7) , col].values * m2_07\n",
    "\n",
    "    data.loc[(data.regMonth==2)&(data.regYear==2018), col] = m2_01_volum/2 + m2_12_volum/4 + m2_11_volum/8 + m2_10_volum/16 + m2_09_volum/32 + m2_08_volum/64 + m2_07_volum/64\n",
    "\n",
    "    #3月\n",
    "    m3_02 = data.loc[(data.regYear==2017)&(data.regMonth==3) , col].values / data.loc[(data.regYear==2017)&(data.regMonth==2 ) , col].values\n",
    "    m3_01 = data.loc[(data.regYear==2017)&(data.regMonth==3) , col].values / data.loc[(data.regYear==2017)&(data.regMonth==1 ) , col].values\n",
    "    m3_12 = data.loc[(data.regYear==2017)&(data.regMonth==3) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==12) , col].values\n",
    "    m3_11 = data.loc[(data.regYear==2017)&(data.regMonth==3) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==11) , col].values\n",
    "    m3_10 = data.loc[(data.regYear==2017)&(data.regMonth==3) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==10) , col].values\n",
    "    m3_09 = data.loc[(data.regYear==2017)&(data.regMonth==3) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==9 ) , col].values\n",
    "    m3_08 = data.loc[(data.regYear==2017)&(data.regMonth==3) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==8 ) , col].values\n",
    "\n",
    "    m3_02_volum = data.loc[(data.regYear==2018)&(data.regMonth==2 ), col].values * m3_02\n",
    "    m3_01_volum = data.loc[(data.regYear==2018)&(data.regMonth==1 ), col].values * m3_01\n",
    "    m3_12_volum = data.loc[(data.regYear==2017)&(data.regMonth==12), col].values * m3_12\n",
    "    m3_11_volum = data.loc[(data.regYear==2017)&(data.regMonth==11), col].values * m3_11\n",
    "    m3_10_volum = data.loc[(data.regYear==2017)&(data.regMonth==10), col].values * m3_10\n",
    "    m3_09_volum = data.loc[(data.regYear==2017)&(data.regMonth==9) , col].values * m3_09\n",
    "    m3_08_volum = data.loc[(data.regYear==2017)&(data.regMonth==8) , col].values * m3_08\n",
    "\n",
    "    data.loc[(data.regMonth==3)&(data.regYear==2018), col] = m3_02_volum/2 + m3_01_volum/4 + m3_12_volum/8 + m3_11_volum/16 + m3_10_volum/32 + m3_09_volum/64 + m3_08_volum/64\n",
    "\n",
    "    #4月\n",
    "    m4_03 = data.loc[(data.regYear==2017)&(data.regMonth==4) , col].values / data.loc[(data.regYear==2017)&(data.regMonth==3 ) , col].values\n",
    "    m4_02 = data.loc[(data.regYear==2017)&(data.regMonth==4) , col].values / data.loc[(data.regYear==2017)&(data.regMonth==2 ) , col].values\n",
    "    m4_01 = data.loc[(data.regYear==2017)&(data.regMonth==4) , col].values / data.loc[(data.regYear==2017)&(data.regMonth==1 ) , col].values\n",
    "    m4_12 = data.loc[(data.regYear==2017)&(data.regMonth==4) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==12) , col].values\n",
    "    m4_11 = data.loc[(data.regYear==2017)&(data.regMonth==4) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==11) , col].values\n",
    "    m4_10 = data.loc[(data.regYear==2017)&(data.regMonth==4) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==10) , col].values\n",
    "    m4_09 = data.loc[(data.regYear==2017)&(data.regMonth==4) , col].values / data.loc[(data.regYear==2016)&(data.regMonth==9 ) , col].values\n",
    "    \n",
    "    m4_03_volum = data.loc[(data.regYear==2018)&(data.regMonth==3 ), col].values * m4_03\n",
    "    m4_02_volum = data.loc[(data.regYear==2018)&(data.regMonth==2 ), col].values * m4_02\n",
    "    m4_01_volum = data.loc[(data.regYear==2018)&(data.regMonth==1 ), col].values * m4_01\n",
    "    m4_12_volum = data.loc[(data.regYear==2017)&(data.regMonth==12), col].values * m4_12\n",
    "    m4_11_volum = data.loc[(data.regYear==2017)&(data.regMonth==11), col].values * m4_11\n",
    "    m4_10_volum = data.loc[(data.regYear==2017)&(data.regMonth==10), col].values * m4_10\n",
    "    m4_09_volum = data.loc[(data.regYear==2017)&(data.regMonth==9 ), col].values * m4_09\n",
    "\n",
    "    data.loc[(data.regMonth==4)&(data.regYear==2018), col] = m4_03_volum/2 + m4_02_volum/4 + m4_01_volum/8 + m4_12_volum/16 + m4_11_volum/32 + m3_10_volum/64 + m4_09_volum/64\n",
    "# 每年的新年在第几月份\n",
    "data['happyNY'] = 0\n",
    "data.loc[(data['regYear'].isin([2016,2018])&data['regMonth'].isin([2])),'happyNY'] = 1\n",
    "data.loc[(data['regYear'].isin([2017])&data['regMonth'].isin([1])),'happyNY'] = 1\n",
    "\n",
    "\n",
    "# label 下移12个月，则测试集填充上了label\n",
    "shift_nums=[4]\n",
    "for i in shift_nums:\n",
    "    shift_feat.append('shift_model_adcode_mt_label_{0}'.format(i))\n",
    "    data['model_adcode_mt_{0}'.format(i)] = data['model_adcode_mt'] + i\n",
    "    data_last = data[~data.label.isnull()].set_index('model_adcode_mt_{0}'.format(i))\n",
    "    data['shift_model_adcode_mt_label_{0}'.format(i)] = data['model_adcode_mt'].map(data_last['label'])\n",
    "window=[1,2,3,4,5,6]\n",
    "m12_1    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==1), 'salesVolume'].values\n",
    "m12_2    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==2), 'salesVolume'].values\n",
    "m12_3    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==3), 'salesVolume'].values\n",
    "m12_4    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==4) , 'salesVolume'].values\n",
    "m12_5    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==5) , 'salesVolume'].values\n",
    "m12_6    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==6) , 'salesVolume'].values\n",
    "m12_7    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==7) , 'salesVolume'].values\n",
    "\n",
    "m12_1_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==1), 'salesVolume'].values * m12_1\n",
    "m12_2_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==2), 'salesVolume'].values * m12_2\n",
    "m12_3_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==3), 'salesVolume'].values * m12_3\n",
    "m12_4_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==4) , 'salesVolume'].values * m12_4\n",
    "m12_5_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==5) , 'salesVolume'].values * m12_5\n",
    "m12_6_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==6) , 'salesVolume'].values * m12_6\n",
    "m12_7_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==7) , 'salesVolume'].values * m12_7\n",
    "\n",
    "data.loc[data.mt==4, 'shift_model_adcode_mt_label_4'] =  m12_1_volum/2 + m12_2_volum/4 + m12_3_volum/8 + \\\n",
    "                                                      m12_4_volum/16 + m12_5_volum/32 + m12_6_volum/64 + m12_7_volum/64\n",
    "\n",
    "m12_1    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12), 'salesVolume'].values\n",
    "m12_2    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==1), 'salesVolume'].values\n",
    "m12_3    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==2), 'salesVolume'].values\n",
    "m12_4    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==3) , 'salesVolume'].values\n",
    "m12_5    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==4) , 'salesVolume'].values\n",
    "m12_6    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==5) , 'salesVolume'].values\n",
    "m12_7    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==6) , 'salesVolume'].values\n",
    "\n",
    "m12_1_volum = data.loc[data.mt==4, 'shift_model_adcode_mt_label_4'].values * m12_1\n",
    "m12_2_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==2), 'salesVolume'].values * m12_2\n",
    "m12_3_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==3), 'salesVolume'].values * m12_3\n",
    "m12_4_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==4) , 'salesVolume'].values * m12_4\n",
    "m12_5_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==5) , 'salesVolume'].values * m12_5\n",
    "m12_6_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==6) , 'salesVolume'].values * m12_6\n",
    "m12_7_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==7) , 'salesVolume'].values * m12_7\n",
    "\n",
    "data.loc[data.mt==3, 'shift_model_adcode_mt_label_4'] =  m12_1_volum/2 + m12_2_volum/4 + m12_3_volum/8 + \\\n",
    "                                                      m12_4_volum/16 + m12_5_volum/32 + m12_6_volum/64 + m12_7_volum/64\n",
    "\n",
    "m12_1    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==10) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11), 'salesVolume'].values\n",
    "m12_2    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==10) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12), 'salesVolume'].values\n",
    "m12_3    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==10) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==1), 'salesVolume'].values\n",
    "m12_4    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==10) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==2) , 'salesVolume'].values\n",
    "m12_5    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==10) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==3) , 'salesVolume'].values\n",
    "m12_6    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==10) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==4) , 'salesVolume'].values\n",
    "m12_7    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==10) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==5) , 'salesVolume'].values\n",
    "\n",
    "m12_1_volum = data.loc[data.mt==3, 'shift_model_adcode_mt_label_4'].values * m12_1\n",
    "m12_2_volum = data.loc[data.mt==4, 'shift_model_adcode_mt_label_4'].values * m12_2\n",
    "m12_3_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==3), 'salesVolume'].values * m12_3\n",
    "m12_4_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==4) , 'salesVolume'].values * m12_4\n",
    "m12_5_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==5) , 'salesVolume'].values * m12_5\n",
    "m12_6_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==6) , 'salesVolume'].values * m12_6\n",
    "m12_7_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==7) , 'salesVolume'].values * m12_7\n",
    "\n",
    "data.loc[data.mt==2, 'shift_model_adcode_mt_label_4'] =  m12_1_volum/2 + m12_2_volum/4 + m12_3_volum/8 + \\\n",
    "                                                      m12_4_volum/16 + m12_5_volum/32 + m12_6_volum/64 + m12_7_volum/64\n",
    "\n",
    "m12_1    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==9) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==10), 'salesVolume'].values\n",
    "m12_2    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==9) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==11), 'salesVolume'].values\n",
    "m12_3    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==9) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==12), 'salesVolume'].values\n",
    "m12_4    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==9) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==1) , 'salesVolume'].values\n",
    "m12_5    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==9) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==2) , 'salesVolume'].values\n",
    "m12_6    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==9) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==3) , 'salesVolume'].values\n",
    "m12_7    = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==9) , 'salesVolume'].values / train_sales.loc[(train_sales.regYear==2017)&(train_sales.regMonth==4) , 'salesVolume'].values\n",
    "\n",
    "m12_1_volum = data.loc[data.mt==2, 'shift_model_adcode_mt_label_4'].values * m12_1\n",
    "m12_2_volum = data.loc[data.mt==3, 'shift_model_adcode_mt_label_4'].values * m12_2\n",
    "m12_3_volum = data.loc[data.mt==4, 'shift_model_adcode_mt_label_4'].values * m12_3\n",
    "m12_4_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==4) , 'salesVolume'].values * m12_4\n",
    "m12_5_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==5) , 'salesVolume'].values * m12_5\n",
    "m12_6_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==6) , 'salesVolume'].values * m12_6\n",
    "m12_7_volum = train_sales.loc[(train_sales.regYear==2016)&(train_sales.regMonth==7) , 'salesVolume'].values * m12_7\n",
    "\n",
    "data.loc[data.mt==1, 'shift_model_adcode_mt_label_4'] =  m12_1_volum/2 + m12_2_volum/4 + m12_3_volum/8 + \\\n",
    "                                                      m12_4_volum/16 + m12_5_volum/32 + m12_6_volum/64 + m12_7_volum/64\n",
    "\n",
    "# 根据月份添加权重值\n",
    "a = 6; b = 4\n",
    "data['weightMonth'] = data['regMonth'].map({1:a, 2:a, 3:a, 4:a,\n",
    "                                            5:b, 6:b, 7:b, 8:b, 9:b, 10:b, 11:b, 12:b,})\n",
    "\n",
    "# 统一取log\n",
    "data['n_carCommentVolum'] = np.log(data['carCommentVolum'])\n",
    "data['n_popularity'] = np.log(data['popularity'])\n",
    "data['n_newsReplyVolum'] = np.log(data['newsReplyVolum'])\n",
    "\n",
    "\n",
    "\n",
    "print(data.mt.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data):\n",
    "    pred = data.groupby(['adcode', 'model'])['pred_label'].agg(lambda x: list(x))\n",
    "    label = data.groupby(['adcode', 'model'])['label'].agg(lambda x: list(x))\n",
    "    label_mean = data.groupby(['adcode', 'model'])['label'].agg(lambda x: np.mean(x))\n",
    "    data_agg = pd.DataFrame()\n",
    "    data_agg['pred_label'] = pred\n",
    "    data_agg['label'] = label\n",
    "    data_agg['label_mean'] = label_mean\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg.values:\n",
    "        nrmse_score.append(mse(raw[0], raw[1]) ** 0.5 / raw[2])\n",
    "    return 1 - np.mean(nrmse_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[300]\tvalid_0's l2: 0.112663\n",
      "[600]\tvalid_0's l2: 0.109477\n",
      "[900]\tvalid_0's l2: 0.107676\n",
      "[1200]\tvalid_0's l2: 0.106518\n",
      "[1500]\tvalid_0's l2: 0.105607\n",
      "[1800]\tvalid_0's l2: 0.104832\n",
      "Early stopping, best iteration is:\n",
      "[1905]\tvalid_0's l2: 0.104673\n",
      "lgb特征重要程度： [('model', 13647), ('adcode', 9484), ('shift_model_adcode_mt_label_4', 9060), ('regMonth', 8099), ('carCommentVolum', 7282), ('popularity', 7249), ('newsReplyVolum', 6805), ('ad_ry_mean', 3040), ('province', 2030), ('n_carCommentVolum', 1493), ('n_popularity', 1349), ('n_newsReplyVolum', 1326), ('regYear', 1160), ('bodyType', 1112), ('happyNY', 828), ('weightMonth', 331)]\n",
      "NRMSE的均值: 0.7412340650361098\n",
      "lgb中forecastVolmn的0值数量： 0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[300]\tvalid_0's l2: 0.111827\n",
      "[600]\tvalid_0's l2: 0.108499\n",
      "[900]\tvalid_0's l2: 0.106398\n",
      "[1200]\tvalid_0's l2: 0.105153\n",
      "[1500]\tvalid_0's l2: 0.104405\n",
      "[1800]\tvalid_0's l2: 0.103888\n",
      "[2100]\tvalid_0's l2: 0.103639\n",
      "Early stopping, best iteration is:\n",
      "[2071]\tvalid_0's l2: 0.103599\n",
      "lgb特征重要程度： [('model', 14450), ('adcode', 10814), ('shift_model_adcode_mt_label_4', 10053), ('regMonth', 8643), ('popularity', 8322), ('carCommentVolum', 7574), ('newsReplyVolum', 7330), ('md_ry_mean', 3422), ('province', 2260), ('n_carCommentVolum', 1630), ('n_newsReplyVolum', 1457), ('n_popularity', 1397), ('regYear', 1221), ('bodyType', 1050), ('happyNY', 809), ('weightMonth', 337)]\n",
      "NRMSE的均值: 0.7413043574557718\n",
      "lgb中forecastVolmn的0值数量： 0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's l2: 0.114771\n",
      "lgb特征重要程度： [('model', 626), ('shift_model_adcode_mt_label_4', 570), ('regMonth', 463), ('adcode', 269), ('popularity', 134), ('carCommentVolum', 109), ('newsReplyVolum', 82), ('weightMonth', 81), ('province', 55), ('regYear', 48), ('happyNY', 33), ('bt_ry_mean', 26), ('n_popularity', 25), ('bodyType', 22), ('n_carCommentVolum', 21), ('n_newsReplyVolum', 10)]\n",
      "NRMSE的均值: 0.7215416684965695\n",
      "lgb中forecastVolmn的0值数量： 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "data['province']=encoder.fit_transform(data['province'])\n",
    "df_lgb = pd.DataFrame({'id': test['id']})\n",
    "for col_add in ['ad_ry_mean', 'md_ry_mean', 'bt_ry_mean']:\n",
    "    # 取用的字段，用于训练模型\n",
    "    num_feat = shift_feat\n",
    "    cate_feat = ['adcode', 'bodyType', 'model', 'regYear', 'regMonth', 'happyNY', 'province']\n",
    "    features = num_feat + cate_feat + ['popularity', 'carCommentVolum', 'newsReplyVolum',\n",
    "                                       'n_popularity', 'n_carCommentVolum', 'n_newsReplyVolum', 'weightMonth'] + [col_add]  # [ad_ry_mean, md_ry_mean, bt_ry_mean]\n",
    " \n",
    "    train_idx = (data['mt'] <= 20) # 小于等于20月以内的数据作为训练集\n",
    "    valid_idx = (data['mt'].between(21, 24)) # 21到24个月的数据作为验证集\n",
    "    test_idx = (data['mt'] > 24) # 大于24个月的是测试集\n",
    " \n",
    "    # label\n",
    "    data['n_label'] = np.log(data['label'])\n",
    " \n",
    "    train_x = data[train_idx][features]\n",
    "    train_y = data[train_idx]['n_label']\n",
    " \n",
    "    valid_x = data[valid_idx][features]\n",
    "    valid_y = data[valid_idx]['n_label']\n",
    " \n",
    "    ############################### lgb ###################################\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        num_leaves=40, reg_alpha=1, reg_lambda=0.1, objective='mse',\n",
    "        max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2019,\n",
    "        n_estimators=8000, subsample=0.8, colsample_bytree=0.8)\n",
    " \n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(valid_x, valid_y)],\n",
    "                  categorical_feature=cate_feat, early_stopping_rounds=100, verbose=300)\n",
    "    data['pred_label'] = np.e ** lgb_model.predict(data[features])\n",
    "    model = lgb_model\n",
    "    # 特征重要程度\n",
    "    print ('lgb特征重要程度：',sorted(dict(zip(train_x.columns,model.feature_importances_)).items(),key=lambda x: x[1], reverse=True))\n",
    "    print('NRMSE的均值:',score(data = data[valid_idx]))\n",
    "    model.n_estimators = model.best_iteration_\n",
    "    model.fit(data[~test_idx][features], data[~test_idx]['n_label'], categorical_feature=cate_feat)\n",
    "    data['forecastVolum'] = np.e ** model.predict(data[features])\n",
    "    sub = data[test_idx][['id']]\n",
    "    sub['forecastVolum'] = data[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    sub_lgb = sub.reset_index(drop=True)\n",
    "    sub_lgb = sub_lgb[['id','forecastVolum']]\n",
    "    print('lgb中forecastVolmn的0值数量：',(sub_lgb['forecastVolum']==0).sum())\n",
    "    df_lgb[col_add] = sub_lgb['forecastVolum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分月"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[300]\tvalid_0's l2: 0.113983\n",
      "[600]\tvalid_0's l2: 0.111103\n",
      "[900]\tvalid_0's l2: 0.109772\n",
      "[1200]\tvalid_0's l2: 0.108185\n",
      "[1500]\tvalid_0's l2: 0.107045\n",
      "[1800]\tvalid_0's l2: 0.106456\n",
      "[2100]\tvalid_0's l2: 0.105942\n",
      "[2400]\tvalid_0's l2: 0.105634\n",
      "Early stopping, best iteration is:\n",
      "[2373]\tvalid_0's l2: 0.105561\n",
      "lgb特征重要程度： [('model', 16334), ('adcode', 11728), ('shift_model_adcode_mt_label_4', 11647), ('popularity', 10077), ('regMonth', 9658), ('carCommentVolum', 9112), ('newsReplyVolum', 8913), ('ad_ry_mean', 5056), ('n_popularity', 2071), ('n_newsReplyVolum', 1946), ('n_carCommentVolum', 1856), ('bodyType', 1495), ('regYear', 1399), ('happyNY', 972), ('weightMonth', 283)]\n",
      "NRMSE的均值: 0.7384237387516983\n",
      "lgb中forecastVolmn的0值数量： 0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[300]\tvalid_0's l2: 0.116467\n",
      "[600]\tvalid_0's l2: 0.113106\n",
      "[900]\tvalid_0's l2: 0.111665\n",
      "[1200]\tvalid_0's l2: 0.110511\n",
      "[1500]\tvalid_0's l2: 0.109371\n",
      "[1800]\tvalid_0's l2: 0.108356\n",
      "[2100]\tvalid_0's l2: 0.107863\n",
      "[2400]\tvalid_0's l2: 0.107621\n",
      "[2700]\tvalid_0's l2: 0.107184\n",
      "[3000]\tvalid_0's l2: 0.106942\n",
      "Early stopping, best iteration is:\n",
      "[2979]\tvalid_0's l2: 0.106874\n",
      "lgb特征重要程度： [('model', 19586), ('shift_model_adcode_mt_label_4', 15316), ('adcode', 14979), ('popularity', 14034), ('regMonth', 11881), ('newsReplyVolum', 11210), ('carCommentVolum', 11149), ('md_ry_mean', 5265), ('n_popularity', 2994), ('n_newsReplyVolum', 2428), ('n_carCommentVolum', 2303), ('regYear', 1731), ('bodyType', 1668), ('happyNY', 1260), ('weightMonth', 377)]\n",
      "NRMSE的均值: 0.7378340919644572\n",
      "lgb中forecastVolmn的0值数量： 0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[300]\tvalid_0's l2: 0.115774\n",
      "[600]\tvalid_0's l2: 0.114077\n",
      "[900]\tvalid_0's l2: 0.112899\n",
      "[1200]\tvalid_0's l2: 0.111599\n",
      "[1500]\tvalid_0's l2: 0.110765\n",
      "[1800]\tvalid_0's l2: 0.109659\n",
      "[2100]\tvalid_0's l2: 0.109021\n",
      "[2400]\tvalid_0's l2: 0.108594\n",
      "Early stopping, best iteration is:\n",
      "[2400]\tvalid_0's l2: 0.108594\n",
      "lgb特征重要程度： [('model', 16503), ('adcode', 12875), ('shift_model_adcode_mt_label_4', 12587), ('popularity', 11132), ('regMonth', 10013), ('carCommentVolum', 9466), ('newsReplyVolum', 9283), ('n_popularity', 2304), ('n_newsReplyVolum', 2051), ('n_carCommentVolum', 1776), ('bt_ry_mean', 1521), ('regYear', 1436), ('bodyType', 1289), ('happyNY', 1030), ('weightMonth', 334)]\n",
      "NRMSE的均值: 0.7353271193441477\n",
      "lgb中forecastVolmn的0值数量： 0\n"
     ]
    }
   ],
   "source": [
    "# 分月\n",
    "df_lgb = pd.DataFrame({'id': test['id']})\n",
    "for col_add in ['ad_ry_mean', 'md_ry_mean', 'bt_ry_mean']:\n",
    "    # 取用的字段，用于训练模型\n",
    "    num_feat = shift_feat\n",
    "    cate_feat = ['adcode', 'bodyType', 'model', 'regYear', 'regMonth', 'happyNY']\n",
    "    features = num_feat + cate_feat + ['popularity', 'carCommentVolum', 'newsReplyVolum', \n",
    "                                       'n_popularity', 'n_carCommentVolum', 'n_newsReplyVolum', 'weightMonth'] + [col_add]  # [ad_ry_mean, md_ry_mean, bt_ry_mean]\n",
    " \n",
    "    train_idx = (data['mt'] <= 20) # 小于等于20月以内的数据作为训练集\n",
    "    valid_idx = (data['mt'].between(21, 24)) # 21到24个月的数据作为验证集\n",
    "    test_idx = (data['mt'] > 24) # 大于24个月的是测试集\n",
    " \n",
    "    # label\n",
    "    data['n_label'] = np.log(data['label'])\n",
    " \n",
    "    train_x = data[train_idx][features]\n",
    "    train_y = data[train_idx]['n_label']\n",
    " \n",
    "    valid_x = data[valid_idx][features]\n",
    "    valid_y = data[valid_idx]['n_label']\n",
    " \n",
    "    ############################### lgb ###################################\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        num_leaves=40, reg_alpha=1, reg_lambda=0.1, objective='mse',\n",
    "        max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2019,\n",
    "        n_estimators=8000, subsample=0.8, colsample_bytree=0.8)\n",
    " \n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(valid_x, valid_y)],\n",
    "                  categorical_feature=cate_feat, early_stopping_rounds=100, verbose=300)\n",
    "    data['pred_label'] = np.e ** lgb_model.predict(data[features])\n",
    "    model = lgb_model\n",
    "    # 特征重要程度\n",
    "    print ('lgb特征重要程度：',sorted(dict(zip(train_x.columns,model.feature_importances_)).items(),key=lambda x: x[1], reverse=True))\n",
    "    print('NRMSE的均值:',score(data = data[valid_idx]))\n",
    "    model.n_estimators = model.best_iteration_\n",
    "    model.fit(data[~test_idx][features], data[~test_idx]['n_label'], categorical_feature=cate_feat)\n",
    "    data['forecastVolum'] = np.e ** model.predict(data[features])\n",
    "    sub = data[test_idx][['id']]\n",
    "    sub['forecastVolum'] = data[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    sub_lgb = sub.reset_index(drop=True)\n",
    "    sub_lgb = sub_lgb[['id','forecastVolum']]\n",
    "    print('lgb中forecastVolmn的0值数量：',(sub_lgb['forecastVolum']==0).sum())\n",
    "    df_lgb[col_add] = sub_lgb['forecastVolum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鱼佬模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2019,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)      \n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 1\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )  \n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)  \n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx]) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features]) \n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)  \n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 8\n",
      "all_idx  : 1 24\n",
      "train_idx: 1 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 36159.2\tvalid_1's l2: 41382.6\n",
      "[200]\ttraining's l2: 22263.4\tvalid_1's l2: 36106.5\n",
      "[300]\ttraining's l2: 16997.1\tvalid_1's l2: 35685.7\n",
      "[400]\ttraining's l2: 14118.9\tvalid_1's l2: 35212.1\n",
      "[500]\ttraining's l2: 12106.3\tvalid_1's l2: 34785.3\n",
      "[600]\ttraining's l2: 10579.4\tvalid_1's l2: 34706.7\n",
      "[700]\ttraining's l2: 9432.25\tvalid_1's l2: 34328.5\n",
      "[800]\ttraining's l2: 8401.27\tvalid_1's l2: 34048.1\n",
      "[900]\ttraining's l2: 7592.19\tvalid_1's l2: 33787.8\n",
      "[1000]\ttraining's l2: 6903.27\tvalid_1's l2: 33794.6\n",
      "Early stopping, best iteration is:\n",
      "[914]\ttraining's l2: 7511.57\tvalid_1's l2: 33660.8\n",
      "0.7398800347208605\n",
      "valid mean: 648.9083797665321\n",
      "true  mean: 646.1667803030306\n",
      "test  mean: 653.3836292495974\n",
      "9 8\n",
      "all_idx  : 1 25\n",
      "train_idx: 1 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 36019.4\tvalid_1's l2: 65571.2\n",
      "[200]\ttraining's l2: 22573.9\tvalid_1's l2: 58809.3\n",
      "[300]\ttraining's l2: 17534.4\tvalid_1's l2: 56877.3\n",
      "[400]\ttraining's l2: 14671.6\tvalid_1's l2: 56838.3\n",
      "[500]\ttraining's l2: 12491.9\tvalid_1's l2: 55234.7\n",
      "[600]\ttraining's l2: 11100.8\tvalid_1's l2: 54817.9\n",
      "[700]\ttraining's l2: 9927.73\tvalid_1's l2: 54722.6\n",
      "Early stopping, best iteration is:\n",
      "[622]\ttraining's l2: 10811.2\tvalid_1's l2: 54616.7\n",
      "0.7079817393267229\n",
      "valid mean: 614.7569783695642\n",
      "true  mean: 616.6704166666672\n",
      "test  mean: 370.9991077262368\n",
      "9 8\n",
      "all_idx  : 1 26\n",
      "train_idx: 1 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 37101.1\tvalid_1's l2: 52112.3\n",
      "[200]\ttraining's l2: 23616.7\tvalid_1's l2: 50561.9\n",
      "[300]\ttraining's l2: 18454.6\tvalid_1's l2: 49909.5\n",
      "[400]\ttraining's l2: 15521.5\tvalid_1's l2: 50275.7\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's l2: 16639.3\tvalid_1's l2: 48828.7\n",
      "0.7224921203136929\n",
      "valid mean: 702.7143567849204\n",
      "true  mean: 672.1217424242425\n",
      "test  mean: 487.4321308470237\n",
      "9 8\n",
      "all_idx  : 1 27\n",
      "train_idx: 1 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 37129\tvalid_1's l2: 105030\n",
      "[200]\ttraining's l2: 23552.2\tvalid_1's l2: 86766.1\n",
      "[300]\ttraining's l2: 18681.9\tvalid_1's l2: 81253.3\n",
      "[400]\ttraining's l2: 15650.5\tvalid_1's l2: 77659.3\n",
      "[500]\ttraining's l2: 13432.7\tvalid_1's l2: 75066.7\n",
      "[600]\ttraining's l2: 11837.4\tvalid_1's l2: 73071.8\n",
      "[700]\ttraining's l2: 10601.3\tvalid_1's l2: 71944.2\n",
      "[800]\ttraining's l2: 9656.94\tvalid_1's l2: 71392.1\n",
      "[900]\ttraining's l2: 8760.42\tvalid_1's l2: 70939.4\n",
      "[1000]\ttraining's l2: 7908.38\tvalid_1's l2: 70553.3\n",
      "[1100]\ttraining's l2: 7213.14\tvalid_1's l2: 70582.7\n",
      "[1200]\ttraining's l2: 6665.44\tvalid_1's l2: 70390.9\n",
      "[1300]\ttraining's l2: 6193.37\tvalid_1's l2: 70199.6\n",
      "[1400]\ttraining's l2: 5805.37\tvalid_1's l2: 69901.2\n",
      "[1500]\ttraining's l2: 5436.89\tvalid_1's l2: 69874.9\n",
      "[1600]\ttraining's l2: 5109.68\tvalid_1's l2: 69950.3\n",
      "Early stopping, best iteration is:\n",
      "[1523]\ttraining's l2: 5367.37\tvalid_1's l2: 69807\n",
      "0.6701653203862457\n",
      "valid mean: 857.940925795135\n",
      "true  mean: 846.1355681818185\n",
      "test  mean: 446.47440612999355\n"
     ]
    }
   ],
   "source": [
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    \n",
    "    data_df = data.copy()\n",
    "    \n",
    "    num_feat = shift_feat\n",
    "    cate_feat = ['adcode', 'bodyType', 'model', 'regYear', 'regMonth', 'happyNY']\n",
    "    features = num_feat + cate_feat + ['popularity', 'carCommentVolum', 'newsReplyVolum', \n",
    "                                       'n_popularity', 'n_carCommentVolum', 'n_newsReplyVolum', 'weightMonth']# + [col_add]  # [ad_ry_mean, md_ry_mean, bt_ry_mean]\n",
    "\n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "           \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values\n",
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','salesVolume']]\n",
    "sub.columns = ['id','forecastVolum']\n",
    "sub[['id','forecastVolum']].round().astype(int).to_csv('../rst/057_feature_yulao_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgb.to_csv(path + \"../rst/057_baseline_allAbnormalClip.csv\", index=False) \n",
    "# df_lgb有三列值，任一一列提交，上0.57，祝各位好运！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3041</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1314</td>\n",
       "      <td>1337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1844</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4356</td>\n",
       "      <td>4423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4864</td>\n",
       "      <td>4931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3891</td>\n",
       "      <td>3958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1725</td>\n",
       "      <td>1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2866</td>\n",
       "      <td>2911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5136</td>\n",
       "      <td>5225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id\n",
       "3041  3086\n",
       "1314  1337\n",
       "1844  1867\n",
       "4356  4423\n",
       "4864  4931\n",
       "3891  3958\n",
       "1725  1748\n",
       "2866  2911\n",
       "5136  5225\n",
       "896    897"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lgb.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('popularity4', 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\gz\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4735\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4736\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4737\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.get_value_at\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\util.pxd\u001b[0m in \u001b[0;36mpandas._libs.util.validate_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0dcbe5f0d0cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'popularity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'popularity%d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\gz\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6911\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6912\u001b[0m         )\n\u001b[1;32m-> 6913\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6915\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gz\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gz\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gz\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-0dcbe5f0d0cd>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'popularity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'popularity%d'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\gz\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gz\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4742\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4743\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4744\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4745\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4746\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\gz\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"getitem\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4729\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4730\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4731\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4732\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('popularity4', 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "data['rate'] = data.apply(lambda x: x['popularity'] / x['popularity%d'%i], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad_ry_mean</th>\n",
       "      <th>adcode</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>bt_ry_mean</th>\n",
       "      <th>carCommentVolum</th>\n",
       "      <th>id</th>\n",
       "      <th>md_ry_mean</th>\n",
       "      <th>model</th>\n",
       "      <th>newsReplyVolum</th>\n",
       "      <th>popularity</th>\n",
       "      <th>regMonth</th>\n",
       "      <th>regYear</th>\n",
       "      <th>label</th>\n",
       "      <th>mt</th>\n",
       "      <th>model_adcode</th>\n",
       "      <th>model_adcode_mt</th>\n",
       "      <th>happyNY</th>\n",
       "      <th>model_adcode_mt_4</th>\n",
       "      <th>shift_model_adcode_mt_label_4</th>\n",
       "      <th>popularity_4_x</th>\n",
       "      <th>weightMonth</th>\n",
       "      <th>n_carCommentVolum</th>\n",
       "      <th>n_popularity</th>\n",
       "      <th>n_newsReplyVolum</th>\n",
       "      <th>popularity_4_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27988</td>\n",
       "      <td>623.000000</td>\n",
       "      <td>510000</td>\n",
       "      <td>0</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>2967.0</td>\n",
       "      <td>1611</td>\n",
       "      <td>938.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>8801.0</td>\n",
       "      <td>5994.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>510012</td>\n",
       "      <td>51001226</td>\n",
       "      <td>1</td>\n",
       "      <td>51001230</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1921.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7.995307</td>\n",
       "      <td>8.698514</td>\n",
       "      <td>9.082621</td>\n",
       "      <td>1921.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6422</td>\n",
       "      <td>413.245833</td>\n",
       "      <td>610000</td>\n",
       "      <td>0</td>\n",
       "      <td>544.339848</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>415.670455</td>\n",
       "      <td>51</td>\n",
       "      <td>1317.0</td>\n",
       "      <td>2459.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2016</td>\n",
       "      <td>293.0</td>\n",
       "      <td>9</td>\n",
       "      <td>610051</td>\n",
       "      <td>61005109</td>\n",
       "      <td>0</td>\n",
       "      <td>61005113</td>\n",
       "      <td>263.0</td>\n",
       "      <td>2154.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.382027</td>\n",
       "      <td>7.807510</td>\n",
       "      <td>7.183112</td>\n",
       "      <td>2154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3733</td>\n",
       "      <td>552.731944</td>\n",
       "      <td>420000</td>\n",
       "      <td>3</td>\n",
       "      <td>453.318182</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>428.791667</td>\n",
       "      <td>49</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>280.0</td>\n",
       "      <td>7</td>\n",
       "      <td>420049</td>\n",
       "      <td>42004907</td>\n",
       "      <td>0</td>\n",
       "      <td>42004911</td>\n",
       "      <td>391.0</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.463832</td>\n",
       "      <td>7.186144</td>\n",
       "      <td>7.612337</td>\n",
       "      <td>1284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14833</td>\n",
       "      <td>521.523611</td>\n",
       "      <td>340000</td>\n",
       "      <td>1</td>\n",
       "      <td>672.187991</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0</td>\n",
       "      <td>640.386364</td>\n",
       "      <td>14</td>\n",
       "      <td>478.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>584.0</td>\n",
       "      <td>16</td>\n",
       "      <td>340014</td>\n",
       "      <td>34001416</td>\n",
       "      <td>0</td>\n",
       "      <td>34001420</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.442418</td>\n",
       "      <td>6.741701</td>\n",
       "      <td>6.169611</td>\n",
       "      <td>665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28581</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>583.0</td>\n",
       "      <td>2204</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>13369.0</td>\n",
       "      <td>5863.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>110039</td>\n",
       "      <td>11003926</td>\n",
       "      <td>1</td>\n",
       "      <td>11003930</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1251.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.368187</td>\n",
       "      <td>8.676417</td>\n",
       "      <td>9.500694</td>\n",
       "      <td>1251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2435</td>\n",
       "      <td>552.731944</td>\n",
       "      <td>420000</td>\n",
       "      <td>1</td>\n",
       "      <td>711.211841</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>400.340909</td>\n",
       "      <td>50</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "      <td>257.0</td>\n",
       "      <td>6</td>\n",
       "      <td>420050</td>\n",
       "      <td>42005006</td>\n",
       "      <td>0</td>\n",
       "      <td>42005010</td>\n",
       "      <td>189.0</td>\n",
       "      <td>4361.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.369448</td>\n",
       "      <td>7.573017</td>\n",
       "      <td>7.339538</td>\n",
       "      <td>4361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9663</td>\n",
       "      <td>571.986111</td>\n",
       "      <td>340000</td>\n",
       "      <td>0</td>\n",
       "      <td>544.339848</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0</td>\n",
       "      <td>873.386364</td>\n",
       "      <td>19</td>\n",
       "      <td>1523.5</td>\n",
       "      <td>2467.0</td>\n",
       "      <td>12</td>\n",
       "      <td>2016</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>12</td>\n",
       "      <td>340019</td>\n",
       "      <td>34001912</td>\n",
       "      <td>0</td>\n",
       "      <td>34001916</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.365976</td>\n",
       "      <td>7.810758</td>\n",
       "      <td>7.328766</td>\n",
       "      <td>2050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27561</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>350000</td>\n",
       "      <td>1</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>442.0</td>\n",
       "      <td>1184</td>\n",
       "      <td>363.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1823.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>350052</td>\n",
       "      <td>35005225</td>\n",
       "      <td>0</td>\n",
       "      <td>35005229</td>\n",
       "      <td>522.0</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.091310</td>\n",
       "      <td>7.508239</td>\n",
       "      <td>-inf</td>\n",
       "      <td>1483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27247</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>360000</td>\n",
       "      <td>0</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>784.0</td>\n",
       "      <td>848</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>38</td>\n",
       "      <td>10111.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>360038</td>\n",
       "      <td>36003825</td>\n",
       "      <td>0</td>\n",
       "      <td>36003829</td>\n",
       "      <td>402.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.664409</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>9.221379</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31498</td>\n",
       "      <td>478.000000</td>\n",
       "      <td>430000</td>\n",
       "      <td>0</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>841.0</td>\n",
       "      <td>5187</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>613.0</td>\n",
       "      <td>1833.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>430051</td>\n",
       "      <td>43005128</td>\n",
       "      <td>0</td>\n",
       "      <td>43005132</td>\n",
       "      <td>357.0</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.734592</td>\n",
       "      <td>7.513709</td>\n",
       "      <td>6.418365</td>\n",
       "      <td>1515.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ad_ry_mean  adcode  bodyType  bt_ry_mean  carCommentVolum    id  \\\n",
       "27988  623.000000  510000         0  459.000000           2967.0  1611   \n",
       "6422   413.245833  610000         0  544.339848             80.0     0   \n",
       "3733   552.731944  420000         3  453.318182            236.0     0   \n",
       "14833  521.523611  340000         1  672.187991            231.0     0   \n",
       "28581  215.000000  110000         0  459.000000            583.0  2204   \n",
       "2435   552.731944  420000         1  711.211841             79.0     0   \n",
       "9663   571.986111  340000         0  544.339848            214.0     0   \n",
       "27561  364.000000  350000         1  654.000000            442.0  1184   \n",
       "27247  351.000000  360000         0  459.000000            784.0   848   \n",
       "31498  478.000000  430000         0  459.000000            841.0  5187   \n",
       "\n",
       "       md_ry_mean  model  newsReplyVolum  popularity  regMonth  regYear  \\\n",
       "27988  938.000000     12          8801.0      5994.0         2     2018   \n",
       "6422   415.670455     51          1317.0      2459.0         9     2016   \n",
       "3733   428.791667     49          2023.0      1321.0         7     2016   \n",
       "14833  640.386364     14           478.0       847.0         4     2017   \n",
       "28581  584.000000     39         13369.0      5863.0         2     2018   \n",
       "2435   400.340909     50          1540.0      1945.0         6     2016   \n",
       "9663   873.386364     19          1523.5      2467.0        12     2016   \n",
       "27561  363.000000     52             0.0      1823.0         1     2018   \n",
       "27247  667.000000     38         10111.0        17.0         1     2018   \n",
       "31498  314.000000     51           613.0      1833.0         4     2018   \n",
       "\n",
       "        label  mt  model_adcode  model_adcode_mt  happyNY  model_adcode_mt_4  \\\n",
       "27988     NaN  26        510012         51001226        1           51001230   \n",
       "6422    293.0   9        610051         61005109        0           61005113   \n",
       "3733    280.0   7        420049         42004907        0           42004911   \n",
       "14833   584.0  16        340014         34001416        0           34001420   \n",
       "28581     NaN  26        110039         11003926        1           11003930   \n",
       "2435    257.0   6        420050         42005006        0           42005010   \n",
       "9663   1490.0  12        340019         34001912        0           34001916   \n",
       "27561     NaN  25        350052         35005225        0           35005229   \n",
       "27247     NaN  25        360038         36003825        0           36003829   \n",
       "31498     NaN  28        430051         43005128        0           43005132   \n",
       "\n",
       "       shift_model_adcode_mt_label_4  popularity_4_x  weightMonth  \\\n",
       "27988                         1043.0          1921.0            6   \n",
       "6422                           263.0          2154.0            4   \n",
       "3733                           391.0          1284.0            4   \n",
       "14833                         1070.0           665.0            6   \n",
       "28581                          121.0          1251.0            6   \n",
       "2435                           189.0          4361.0            4   \n",
       "9663                           980.0          2050.0            4   \n",
       "27561                          522.0          1483.0            6   \n",
       "27247                          402.0            95.0            6   \n",
       "31498                          357.0          1515.0            6   \n",
       "\n",
       "       n_carCommentVolum  n_popularity  n_newsReplyVolum  popularity_4_y  \n",
       "27988           7.995307      8.698514          9.082621          1921.0  \n",
       "6422            4.382027      7.807510          7.183112          2154.0  \n",
       "3733            5.463832      7.186144          7.612337          1284.0  \n",
       "14833           5.442418      6.741701          6.169611           665.0  \n",
       "28581           6.368187      8.676417          9.500694          1251.0  \n",
       "2435            4.369448      7.573017          7.339538          4361.0  \n",
       "9663            5.365976      7.810758          7.328766          2050.0  \n",
       "27561           6.091310      7.508239              -inf          1483.0  \n",
       "27247           6.664409      2.833213          9.221379            95.0  \n",
       "31498           6.734592      7.513709          6.418365          1515.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.merge(tmp,on='model_adcode_mt').sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lgb = pd.DataFrame({'id': test['id']})\n",
    "for col_add in ['ad_ry_mean', 'md_ry_mean', 'bt_ry_mean']:\n",
    "    # 取用的字段，用于训练模型\n",
    "    num_feat = shift_feat\n",
    "    cate_feat = ['adcode', 'bodyType', 'model', 'regYear', 'regMonth', 'happyNY']\n",
    "    features = num_feat + cate_feat + ['popularity', 'carCommentVolum', 'newsReplyVolum', \n",
    "                                       'n_popularity', 'n_carCommentVolum', 'n_newsReplyVolum', 'weightMonth'] + [col_add]  # [ad_ry_mean, md_ry_mean, bt_ry_mean]\n",
    " \n",
    "    train_idx = (data['mt'] <= 20) # 小于等于20月以内的数据作为训练集\n",
    "    valid_idx = (data['mt'].between(21, 24)) # 21到24个月的数据作为验证集\n",
    "    test_idx = (data['mt'] > 24) # 大于24个月的是测试集\n",
    " \n",
    "    # label\n",
    "    data['n_label'] = np.log(data['label'])\n",
    " \n",
    "    train_x = data[train_idx][features]\n",
    "    train_y = data[train_idx]['n_label']\n",
    " \n",
    "    valid_x = data[valid_idx][features]\n",
    "    valid_y = data[valid_idx]['n_label']\n",
    " \n",
    "    ############################### lgb ###################################\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        num_leaves=40, reg_alpha=1, reg_lambda=0.1, objective='mse',\n",
    "        max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2019,\n",
    "        n_estimators=8000, subsample=0.8, colsample_bytree=0.8)\n",
    " \n",
    "    lgb_model.fit(train_x, train_y, eval_set=[(valid_x, valid_y)],\n",
    "                  categorical_feature=cate_feat, early_stopping_rounds=100, verbose=300)\n",
    "    data['pred_label'] = np.e ** lgb_model.predict(data[features])\n",
    "    model = lgb_model\n",
    "    # 特征重要程度\n",
    "    print ('lgb特征重要程度：',sorted(dict(zip(train_x.columns,model.feature_importances_)).items(),key=lambda x: x[1], reverse=True))\n",
    "    print('NRMSE的均值:',score(data = data[valid_idx]))\n",
    "    model.n_estimators = model.best_iteration_\n",
    "    model.fit(data[~test_idx][features], data[~test_idx]['n_label'], categorical_feature=cate_feat)\n",
    "    data['forecastVolum'] = np.e ** model.predict(data[features])\n",
    "    sub = data[test_idx][['id']]\n",
    "    sub['forecastVolum'] = data[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    sub_lgb = sub.reset_index(drop=True)\n",
    "    sub_lgb = sub_lgb[['id','forecastVolum']]\n",
    "    print('lgb中forecastVolmn的0值数量：',(sub_lgb['forecastVolum']==0).sum())\n",
    "    df_lgb[col_add] = sub_lgb['forecastVolum']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
