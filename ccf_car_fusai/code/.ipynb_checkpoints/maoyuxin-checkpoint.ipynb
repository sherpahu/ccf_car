{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.87it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 27.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:742.849\tvalidation_1-rmse:916.995\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:702.771\tvalidation_1-rmse:876.321\n",
      "[200]\tvalidation_0-rmse:222.565\tvalidation_1-rmse:354.341\n",
      "[300]\tvalidation_0-rmse:123.294\tvalidation_1-rmse:245.748\n",
      "[400]\tvalidation_0-rmse:107.931\tvalidation_1-rmse:238.778\n",
      "[500]\tvalidation_0-rmse:99.3993\tvalidation_1-rmse:236.557\n",
      "[600]\tvalidation_0-rmse:90.9904\tvalidation_1-rmse:232.451\n",
      "[700]\tvalidation_0-rmse:86.105\tvalidation_1-rmse:231.115\n",
      "[800]\tvalidation_0-rmse:81.0385\tvalidation_1-rmse:231.079\n",
      "[900]\tvalidation_0-rmse:76.7003\tvalidation_1-rmse:230.648\n",
      "[1000]\tvalidation_0-rmse:72.2561\tvalidation_1-rmse:228.458\n",
      "[1100]\tvalidation_0-rmse:68.6501\tvalidation_1-rmse:227.311\n",
      "[1200]\tvalidation_0-rmse:65.4614\tvalidation_1-rmse:225.554\n",
      "[1300]\tvalidation_0-rmse:62.275\tvalidation_1-rmse:225.276\n",
      "[1400]\tvalidation_0-rmse:59.2922\tvalidation_1-rmse:225.09\n",
      "[1500]\tvalidation_0-rmse:57.0289\tvalidation_1-rmse:224.336\n",
      "[1600]\tvalidation_0-rmse:54.6704\tvalidation_1-rmse:224.407\n",
      "Stopping. Best iteration:\n",
      "[1505]\tvalidation_0-rmse:56.9164\tvalidation_1-rmse:224.13\n",
      "\n",
      "0.7571041679857837\n",
      "valid mean: 499.0296325683594\n",
      "true  mean: 559.1185785586853\n",
      "test  mean: 464.5069885253906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  3.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 27.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:764.161\tvalidation_1-rmse:881.979\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:724.045\tvalidation_1-rmse:842.767\n",
      "[200]\tvalidation_0-rmse:229.363\tvalidation_1-rmse:435.032\n",
      "[300]\tvalidation_0-rmse:123.235\tvalidation_1-rmse:378.546\n",
      "[400]\tvalidation_0-rmse:110.499\tvalidation_1-rmse:377.78\n",
      "[500]\tvalidation_0-rmse:102.6\tvalidation_1-rmse:379.815\n",
      "Stopping. Best iteration:\n",
      "[435]\tvalidation_0-rmse:107.415\tvalidation_1-rmse:376.813\n",
      "\n",
      "0.5680454367352807\n",
      "valid mean: 364.9231872558594\n",
      "true  mean: 531.3914267715669\n",
      "test  mean: 336.1412048339844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  3.01it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 27.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:776.747\tvalidation_1-rmse:939.855\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:736.65\tvalidation_1-rmse:899.532\n",
      "[200]\tvalidation_0-rmse:237.025\tvalidation_1-rmse:422.125\n",
      "[300]\tvalidation_0-rmse:131.544\tvalidation_1-rmse:328.373\n",
      "[400]\tvalidation_0-rmse:117.682\tvalidation_1-rmse:319.741\n",
      "Stopping. Best iteration:\n",
      "[389]\tvalidation_0-rmse:118.266\tvalidation_1-rmse:319.349\n",
      "\n",
      "0.6671840992711282\n",
      "valid mean: 436.0978698730469\n",
      "true  mean: 577.0072390614604\n",
      "test  mean: 370.2229309082031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:792.963\tvalidation_1-rmse:1271.5\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:752.784\tvalidation_1-rmse:1230.87\n",
      "[200]\tvalidation_0-rmse:243.32\tvalidation_1-rmse:707.234\n",
      "[300]\tvalidation_0-rmse:129.555\tvalidation_1-rmse:636.811\n",
      "Stopping. Best iteration:\n",
      "[234]\tvalidation_0-rmse:157.385\tvalidation_1-rmse:632.894\n",
      "\n",
      "0.38363959207905995\n",
      "valid mean: 395.715576171875\n",
      "true  mean: 768.2413899779178\n",
      "test  mean: 361.51641845703125\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    #mask=~data['salesVolume'].isnull()\n",
    "    #data['salesVolume'][mask] = exponential_smoothing(data['salesVolume'][mask],0.95)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'xgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/car_prediction_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 平滑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple\n",
    "\n",
    "# given a series and alpha, return series of smoothed points\n",
    "def exponential_smoothing(series, alpha):\n",
    "#     result = [series[0]] # first value is same as series\n",
    "    result = [sum(series)/len(series)] #avg for first value\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return result\n",
    "\n",
    "#double\n",
    "\n",
    "# given a series and alpha, return series of smoothed points\n",
    "def exponential_smoothing(series, alpha):\n",
    "#     result = [series[0]] # first value is same as series\n",
    "    result = [sum(series)/len(series)] #avg for first value\n",
    "    for n in range(1, len(series)):\n",
    "        result.append(alpha * series[n] + (1 - alpha) * result[n-1])\n",
    "    return result\n",
    "\n",
    "#triple\n",
    "def initial_trend(series, slen):\n",
    "    sum = 0.0\n",
    "    for i in range(slen):\n",
    "        sum += float(series[i+slen] - series[i]) / slen\n",
    "    return sum / slen\n",
    "def initial_seasonal_components(series, slen):\n",
    "    seasonals = {}\n",
    "    season_averages = []\n",
    "    n_seasons = int(len(series)/slen)\n",
    "    # compute season averages\n",
    "    for j in range(n_seasons):\n",
    "        season_averages.append(sum(series[slen*j:slen*j+slen])/float(slen))\n",
    "    # compute initial values\n",
    "    for i in range(slen):\n",
    "        sum_of_vals_over_avg = 0.0\n",
    "        for j in range(n_seasons):\n",
    "            sum_of_vals_over_avg += series[slen*j+i]-season_averages[j]\n",
    "        seasonals[i] = sum_of_vals_over_avg/n_seasons\n",
    "    return seasonals\n",
    "def triple_exponential_smoothing(series, slen, alpha, beta, gamma, n_preds):\n",
    "    result = []\n",
    "    seasonals = initial_seasonal_components(series, slen)\n",
    "    for i in range(len(series)+n_preds):\n",
    "        if i == 0: # initial values\n",
    "            smooth = series[0]\n",
    "            trend = initial_trend(series, slen)\n",
    "            result.append(series[0])\n",
    "            continue\n",
    "        if i >= len(series): # we are forecasting\n",
    "            m = i - len(series) + 1\n",
    "            result.append((smooth + m*trend) + seasonals[i%slen])\n",
    "        else:\n",
    "            val = series[i]\n",
    "            last_smooth, smooth = smooth, alpha*(val-seasonals[i%slen]) + (1-alpha)*(smooth+trend)\n",
    "            trend = beta * (smooth-last_smooth) + (1-beta)*trend\n",
    "            seasonals[i%slen] = gamma*(val-smooth) + (1-gamma)*seasonals[i%slen]\n",
    "            result.append(smooth+trend+seasonals[i%slen])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regYear</th>\n",
       "      <th>shift_model_adcode_mt_label_1</th>\n",
       "      <th>shift_model_adcode_mt_label_2</th>\n",
       "      <th>shift_model_adcode_mt_label_3</th>\n",
       "      <th>shift_model_adcode_mt_label_4</th>\n",
       "      <th>shift_model_adcode_mt_label_5</th>\n",
       "      <th>shift_model_adcode_mt_label_6</th>\n",
       "      <th>shift_model_adcode_mt_label_7</th>\n",
       "      <th>shift_model_adcode_mt_label_8</th>\n",
       "      <th>shift_model_adcode_mt_label_9</th>\n",
       "      <th>shift_model_adcode_mt_popularity_1</th>\n",
       "      <th>shift_model_adcode_mt_popularity_2</th>\n",
       "      <th>shift_model_adcode_mt_popularity_3</th>\n",
       "      <th>shift_model_adcode_mt_popularity_4</th>\n",
       "      <th>shift_model_adcode_mt_popularity_5</th>\n",
       "      <th>shift_model_adcode_mt_popularity_6</th>\n",
       "      <th>shift_model_adcode_mt_popularity_7</th>\n",
       "      <th>shift_model_adcode_mt_popularity_8</th>\n",
       "      <th>shift_model_adcode_mt_popularity_9</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_1</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_2</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_3</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_4</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_5</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_6</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_7</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_8</th>\n",
       "      <th>shift_model_adcode_mt_area_sales_volume_9</th>\n",
       "      <th>adcode</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>model</th>\n",
       "      <th>regMonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   regYear  shift_model_adcode_mt_label_1  shift_model_adcode_mt_label_2  \\\n",
       "0     2016                            NaN                            NaN   \n",
       "1     2016                            NaN                            NaN   \n",
       "2     2016                            NaN                            NaN   \n",
       "3     2016                            NaN                            NaN   \n",
       "4     2016                            NaN                            NaN   \n",
       "\n",
       "   shift_model_adcode_mt_label_3  shift_model_adcode_mt_label_4  \\\n",
       "0                            NaN                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   shift_model_adcode_mt_label_5  shift_model_adcode_mt_label_6  \\\n",
       "0                            NaN                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   shift_model_adcode_mt_label_7  shift_model_adcode_mt_label_8  \\\n",
       "0                            NaN                            NaN   \n",
       "1                            NaN                            NaN   \n",
       "2                            NaN                            NaN   \n",
       "3                            NaN                            NaN   \n",
       "4                            NaN                            NaN   \n",
       "\n",
       "   shift_model_adcode_mt_label_9  shift_model_adcode_mt_popularity_1  \\\n",
       "0                            NaN                                 NaN   \n",
       "1                            NaN                                 NaN   \n",
       "2                            NaN                                 NaN   \n",
       "3                            NaN                                 NaN   \n",
       "4                            NaN                                 NaN   \n",
       "\n",
       "   shift_model_adcode_mt_popularity_2  shift_model_adcode_mt_popularity_3  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "   shift_model_adcode_mt_popularity_4  shift_model_adcode_mt_popularity_5  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "   shift_model_adcode_mt_popularity_6  shift_model_adcode_mt_popularity_7  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "   shift_model_adcode_mt_popularity_8  shift_model_adcode_mt_popularity_9  \\\n",
       "0                                 NaN                                 NaN   \n",
       "1                                 NaN                                 NaN   \n",
       "2                                 NaN                                 NaN   \n",
       "3                                 NaN                                 NaN   \n",
       "4                                 NaN                                 NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_1  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_2  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_3  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_4  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_5  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_6  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_7  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_8  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   shift_model_adcode_mt_area_sales_volume_9  adcode  bodyType  model  \\\n",
       "0                                        NaN       6         0      0   \n",
       "1                                        NaN      20         0      0   \n",
       "2                                        NaN       3         0      0   \n",
       "3                                        NaN       0         0      0   \n",
       "4                                        NaN      19         0      0   \n",
       "\n",
       "   regMonth  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regYear',\n",
       " 'shift_model_adcode_mt_label_1',\n",
       " 'shift_model_adcode_mt_label_2',\n",
       " 'shift_model_adcode_mt_label_3',\n",
       " 'shift_model_adcode_mt_label_4',\n",
       " 'shift_model_adcode_mt_label_5',\n",
       " 'shift_model_adcode_mt_label_6',\n",
       " 'shift_model_adcode_mt_label_7',\n",
       " 'shift_model_adcode_mt_label_8',\n",
       " 'shift_model_adcode_mt_label_9',\n",
       " 'shift_model_adcode_mt_popularity_1',\n",
       " 'shift_model_adcode_mt_popularity_2',\n",
       " 'shift_model_adcode_mt_popularity_3',\n",
       " 'shift_model_adcode_mt_popularity_4',\n",
       " 'shift_model_adcode_mt_popularity_5',\n",
       " 'shift_model_adcode_mt_popularity_6',\n",
       " 'shift_model_adcode_mt_popularity_7',\n",
       " 'shift_model_adcode_mt_popularity_8',\n",
       " 'shift_model_adcode_mt_popularity_9',\n",
       " 'shift_model_adcode_mt_area_sales_volume_1',\n",
       " 'shift_model_adcode_mt_area_sales_volume_2',\n",
       " 'shift_model_adcode_mt_area_sales_volume_3',\n",
       " 'shift_model_adcode_mt_area_sales_volume_4',\n",
       " 'shift_model_adcode_mt_area_sales_volume_5',\n",
       " 'shift_model_adcode_mt_area_sales_volume_6',\n",
       " 'shift_model_adcode_mt_area_sales_volume_7',\n",
       " 'shift_model_adcode_mt_area_sales_volume_8',\n",
       " 'shift_model_adcode_mt_area_sales_volume_9',\n",
       " 'adcode',\n",
       " 'bodyType',\n",
       " 'model',\n",
       " 'regMonth']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adcode</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>forecastVolum</th>\n",
       "      <th>id</th>\n",
       "      <th>model</th>\n",
       "      <th>province</th>\n",
       "      <th>regMonth</th>\n",
       "      <th>regYear</th>\n",
       "      <th>salesVolume</th>\n",
       "      <th>popularity</th>\n",
       "      <th>carCommentVolum</th>\n",
       "      <th>newsReplyVolum</th>\n",
       "      <th>label</th>\n",
       "      <th>mt</th>\n",
       "      <th>area_sales_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>310000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>上海</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>292.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>530000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>云南</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>466.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>1</td>\n",
       "      <td>36511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>内蒙古</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>110000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>北京</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>408.0</td>\n",
       "      <td>2370.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>1</td>\n",
       "      <td>43567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>510000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>四川</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>610.0</td>\n",
       "      <td>3562.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>610.0</td>\n",
       "      <td>1</td>\n",
       "      <td>72231.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adcode  bodyType  forecastVolum  id  model province  regMonth  regYear  \\\n",
       "0  310000         0            NaN   0      0       上海         1     2016   \n",
       "1  530000         0            NaN   0      0       云南         1     2016   \n",
       "2  150000         0            NaN   0      0      内蒙古         1     2016   \n",
       "3  110000         0            NaN   0      0       北京         1     2016   \n",
       "4  510000         0            NaN   0      0       四川         1     2016   \n",
       "\n",
       "   salesVolume  popularity  carCommentVolum  newsReplyVolum  label  mt  \\\n",
       "0        292.0      1479.0             11.0           106.0  292.0   1   \n",
       "1        466.0      1594.0             11.0           106.0  466.0   1   \n",
       "2        257.0      1479.0             11.0           106.0  257.0   1   \n",
       "3        408.0      2370.0             11.0           106.0  408.0   1   \n",
       "4        610.0      3562.0             11.0           106.0  610.0   1   \n",
       "\n",
       "   area_sales_volume  \n",
       "0            38525.0  \n",
       "1            36511.0  \n",
       "2            25295.0  \n",
       "3            43567.0  \n",
       "4            72231.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=~data['salesVolume'].isnull()\n",
    "data['salesVolume'][mask] = exponential_smoothing(data['salesVolume'][mask],0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[532.8333102365115,\n",
       " 469.34166551182557,\n",
       " 267.61708327559126,\n",
       " 400.98085416377955,\n",
       " 599.549042708189,\n",
       " 225.67745213540945,\n",
       " 489.13387260677047,\n",
       " 248.65669363033854,\n",
       " 3465.682834681517,\n",
       " 600.784141734076,\n",
       " 862.2392070867038,\n",
       " 283.46196035433525,\n",
       " 304.87309801771676,\n",
       " 525.3936549008858,\n",
       " 643.7696827450443,\n",
       " 635.4384841372522,\n",
       " 530.5219242068626,\n",
       " 465.42609621034313,\n",
       " 774.7213048105172,\n",
       " 223.98606524052587,\n",
       " 294.2993032620263,\n",
       " 308.26496516310135,\n",
       " 384.96324825815503,\n",
       " 309.9481624129078,\n",
       " 262.4974081206454,\n",
       " 439.67487040603226,\n",
       " 741.1337435203017,\n",
       " 298.3066871760151,\n",
       " 860.4153343588008,\n",
       " 410.67076671794007,\n",
       " 7934.033538335897,\n",
       " 1157.6516769167952,\n",
       " 1658.63258384584,\n",
       " 456.28162919229203,\n",
       " 771.4140814596145,\n",
       " 846.0707040729808,\n",
       " 1408.403535203649,\n",
       " 794.3201767601824,\n",
       " 683.8160088380092,\n",
       " 1093.4408004419006,\n",
       " 1293.472040022095,\n",
       " 243.2736020011048,\n",
       " 240.16368010005525,\n",
       " 455.65818400500274,\n",
       " 243.18290920025012,\n",
       " 294.3091454600125,\n",
       " 260.7654572730006,\n",
       " 777.78827286365,\n",
       " 440.7394136431825,\n",
       " 153.13697068215913,\n",
       " 327.8068485341079,\n",
       " 174.0903424267054,\n",
       " 1694.9545171213354,\n",
       " 281.3977258560668,\n",
       " 453.9198862928033,\n",
       " 114.84599431464018,\n",
       " 315.442299715732,\n",
       " 273.2221149857866,\n",
       " 375.6111057492893,\n",
       " 233.48055528746448,\n",
       " 257.7240277643732,\n",
       " 143.03620138821867,\n",
       " 523.0018100694109,\n",
       " 189.55009050347059,\n",
       " 245.07750452517354,\n",
       " 356.15387522625866,\n",
       " 248.65769376131294,\n",
       " 238.53288468806565,\n",
       " 192.42664423440328,\n",
       " 327.8713322117202,\n",
       " 517.993566610586,\n",
       " 318.49967833052926,\n",
       " 418.7249839165264,\n",
       " 193.83624919582635,\n",
       " 4056.6918124597914,\n",
       " 596.1345906229897,\n",
       " 886.7067295311494,\n",
       " 279.9353364765575,\n",
       " 402.54676682382785,\n",
       " 452.37733834119143,\n",
       " 1010.6188669170596,\n",
       " 691.7809433458531,\n",
       " 554.2390471672927,\n",
       " 468.5119523583646,\n",
       " 639.9755976179182,\n",
       " 209.64877988089594,\n",
       " 256.5324389940448,\n",
       " 289.27662194970225,\n",
       " 361.2138310974851,\n",
       " 3957.710691554874,\n",
       " 736.5355345777439,\n",
       " 470.0267767288872,\n",
       " 1706.9013388364442,\n",
       " 2259.895066941822,\n",
       " 5319.944753347091,\n",
       " 2323.697237667355,\n",
       " 2128.2848618833677,\n",
       " 4646.4642430941685,\n",
       " 2472.4232121547084,\n",
       " 1911.5211606077355,\n",
       " 4001.9760580303864,\n",
       " 6898.54880290152,\n",
       " 1685.3774401450764,\n",
       " 1911.1188720072537,\n",
       " 2600.705943600363,\n",
       " 766.5352971800182,\n",
       " 1181.1767648590007,\n",
       " 410.55883824295006,\n",
       " 2569.3779419121474,\n",
       " 813.4188970956075,\n",
       " 450.1209448547804,\n",
       " 258.106047242739,\n",
       " 904.9553023621369,\n",
       " 480.34776511810685,\n",
       " 1183.9673882559055,\n",
       " 1427.1983694127953,\n",
       " 1645.5099184706396,\n",
       " 689.325495923532,\n",
       " 6154.366274796176,\n",
       " 990.7683137398091,\n",
       " 2009.3884156869904,\n",
       " 1116.9694207843495,\n",
       " 1742.0984710392174,\n",
       " 2444.0549235519607,\n",
       " 1220.4027461775981,\n",
       " 1741.57013730888,\n",
       " 1837.928506865444,\n",
       " 430.09642534327224,\n",
       " 305.5548212671636,\n",
       " 747.7277410633582,\n",
       " 535.1863870531679,\n",
       " 601.5093193526584,\n",
       " 1149.1754659676328,\n",
       " 130.6087732983817,\n",
       " 70.1804386649191,\n",
       " 1020.9590219332459,\n",
       " 199.24795109666235,\n",
       " 151.51239755483311,\n",
       " 610.8256198777417,\n",
       " 156.8912809938871,\n",
       " 563.5945640496943,\n",
       " 83.27972820248473,\n",
       " 706.2139864101242,\n",
       " 121.76069932050625,\n",
       " 243.5880349660253,\n",
       " 376.02940174830127,\n",
       " 394.05147008741505,\n",
       " 123.25257350437077,\n",
       " 82.16262867521854,\n",
       " 77.25813143376092,\n",
       " 155.86290657168806,\n",
       " 84.74314532858442,\n",
       " 170.48715726642922,\n",
       " 111.12435786332146,\n",
       " 947.956217893166,\n",
       " 228.84781089465832,\n",
       " 108.34239054473292,\n",
       " 204.91711952723665,\n",
       " 417.7958559763618,\n",
       " 744.7897927988181,\n",
       " 890.3394896399409,\n",
       " 152.81697448199708,\n",
       " 586.1908487240999,\n",
       " 190.80954243620502,\n",
       " 1820.24047712181,\n",
       " 417.8120238560906,\n",
       " 285.94060119280454,\n",
       " 544.3970300596403,\n",
       " 1514.9198515029818,\n",
       " 506.0959925751491,\n",
       " 461.3547996287574,\n",
       " 248.21773998143786,\n",
       " 162.5108869990719,\n",
       " 85.0755443499536,\n",
       " 265.50377721749766,\n",
       " 49.3751888608749,\n",
       " 1495.8687594430437,\n",
       " 656.1934379721522,\n",
       " 472.6596718986076,\n",
       " 873.8829835949304,\n",
       " 1389.8441491797464,\n",
       " 1227.5422074589874,\n",
       " 2190.3271103729494,\n",
       " 752.6663555186476,\n",
       " 2175.1333177759325,\n",
       " 673.0566658887967,\n",
       " 2116.05283329444,\n",
       " 1114.702641664722,\n",
       " 1032.335132083236,\n",
       " 1597.2667566041616,\n",
       " 1654.013337830208,\n",
       " 1517.2006668915105,\n",
       " 1643.3600333445756,\n",
       " 889.6680016672289,\n",
       " 468.18340008336145,\n",
       " 536.4091700041681,\n",
       " 735.5204585002084,\n",
       " 289.47602292501045,\n",
       " 1638.0238011462504,\n",
       " 452.4011900573126,\n",
       " 552.7200595028656,\n",
       " 344.9360029751433,\n",
       " 1641.746800148757,\n",
       " 2338.337340007438,\n",
       " 3653.766867000372,\n",
       " 796.3883433500187,\n",
       " 1727.9694171675008,\n",
       " 729.5484708583751,\n",
       " 4784.577423542918,\n",
       " 1437.1788711771462,\n",
       " 1906.3089435588572,\n",
       " 2568.165447177943,\n",
       " 3074.358272358897,\n",
       " 1846.6179136179449,\n",
       " 1694.9808956808972,\n",
       " 933.0990447840448,\n",
       " 606.2049522392023,\n",
       " 381.81024761196016,\n",
       " 723.040512380598,\n",
       " 320.20202561902994,\n",
       " 209.8101012809515,\n",
       " 185.29050506404758,\n",
       " 378.81452525320236,\n",
       " 215.5907262626601,\n",
       " 918.029536313133,\n",
       " 798.3014768156567,\n",
       " 1867.715073840783,\n",
       " 522.7857536920392,\n",
       " 1188.9392876846018,\n",
       " 532.5469643842301,\n",
       " 1035.5273482192115,\n",
       " 1048.3263674109605,\n",
       " 925.466318370548,\n",
       " 2069.7733159185273,\n",
       " 1793.5386657959264,\n",
       " 935.1769332897964,\n",
       " 1494.55884666449,\n",
       " 712.1779423332245,\n",
       " 238.90889711666125,\n",
       " 371.045444855833,\n",
       " 899.2022722427917,\n",
       " 228.31011361213962,\n",
       " 85.51550568060699,\n",
       " 328.22577528403036,\n",
       " 350.8112887642015,\n",
       " 240.79056443821008,\n",
       " 730.2395282219104,\n",
       " 381.3619764110955,\n",
       " 1718.6180988205547,\n",
       " 493.48090494102775,\n",
       " 633.6240452470513,\n",
       " 302.4312022623526,\n",
       " 436.9215601131176,\n",
       " 522.4960780056559,\n",
       " 1239.2748039002827,\n",
       " 1451.8137401950141,\n",
       " 500.09068700975075,\n",
       " 430.65453435048755,\n",
       " 875.5827267175243,\n",
       " 234.72913633587623,\n",
       " 291.9864568167938,\n",
       " 221.6993228408397,\n",
       " 756.834966142042,\n",
       " 296.2417483071021,\n",
       " 318.8120874153551,\n",
       " 761.6906043707678,\n",
       " 382.9345302185384,\n",
       " 363.04672651092693,\n",
       " 1722.4523363255464,\n",
       " 1257.4726168162774,\n",
       " 1404.273630840814,\n",
       " 539.5136815420407,\n",
       " 1522.275684077102,\n",
       " 576.7637842038552,\n",
       " 1540.2881892101925,\n",
       " 936.7644094605097,\n",
       " 1275.1882204730255,\n",
       " 1503.0094110236514,\n",
       " 1843.1004705511825,\n",
       " 1159.0050235275592,\n",
       " 1083.950251176378,\n",
       " 518.7475125588189,\n",
       " 359.38737562794097,\n",
       " 454.019368781397,\n",
       " 696.2509684390699,\n",
       " 592.4625484219534,\n",
       " 857.0731274210976,\n",
       " 1661.653656371055,\n",
       " 789.8826828185528,\n",
       " 954.3441341409276,\n",
       " 3264.4172067070463,\n",
       " 2373.8708603353525,\n",
       " 3214.7435430167675,\n",
       " 1001.4871771508385,\n",
       " 3316.174358857542,\n",
       " 1018.9087179428772,\n",
       " 3657.1454358971437,\n",
       " 1698.1072717948573,\n",
       " 2503.605363589743,\n",
       " 4463.830268179487,\n",
       " 3698.2915134089744,\n",
       " 2480.1145756704486,\n",
       " 2536.055728783522,\n",
       " 905.8027864391762,\n",
       " 963.9401393219588,\n",
       " 1086.5470069660978,\n",
       " 1181.9773503483048,\n",
       " 816.2488675174153,\n",
       " 1329.9624433758706,\n",
       " 609.8981221687935,\n",
       " 623.2949061084397,\n",
       " 1735.464745305422,\n",
       " 973.1232372652711,\n",
       " 1158.2561618632635,\n",
       " 1904.7128080931632,\n",
       " 1248.5356404046581,\n",
       " 577.3267820202329,\n",
       " 235.96633910101167,\n",
       " 2205.3483169550504,\n",
       " 796.1674158477526,\n",
       " 1831.5083707923875,\n",
       " 1589.7254185396193,\n",
       " 1137.786270926981,\n",
       " 553.7393135463491,\n",
       " 737.3369656773175,\n",
       " 591.6668482838659,\n",
       " 279.4333424141933,\n",
       " 773.9716671207096,\n",
       " 788.2485833560355,\n",
       " 213.2624291678018,\n",
       " 54.3631214583901,\n",
       " 1223.4681560729196,\n",
       " 1309.473407803646,\n",
       " 963.2236703901824,\n",
       " 2159.061183519509,\n",
       " 684.6030591759755,\n",
       " 3859.8801529587986,\n",
       " 1365.2940076479401,\n",
       " 1546.4647003823968,\n",
       " 545.6732350191198,\n",
       " 898.4336617509559,\n",
       " 516.1216830875478,\n",
       " 3578.8060841543775,\n",
       " 2610.9403042077192,\n",
       " 890.547015210386,\n",
       " 843.4773507605192,\n",
       " 2180.623867538026,\n",
       " 857.6311933769014,\n",
       " 1324.431559668845,\n",
       " 288.5215779834423,\n",
       " 1071.776078899172,\n",
       " 1472.8888039449587,\n",
       " 2329.894440197248,\n",
       " 1075.0447220098624,\n",
       " 760.5522361004931,\n",
       " 1432.6276118050246,\n",
       " 2410.5313805902515,\n",
       " 3048.4265690295124,\n",
       " 5379.321328451475,\n",
       " 2238.316066422574,\n",
       " 2647.4658033211285,\n",
       " 818.2732901660565,\n",
       " 5389.413664508303,\n",
       " 2828.7706832254153,\n",
       " 4431.63853416127,\n",
       " 4583.981926708063,\n",
       " 3193.1990963354033,\n",
       " 2620.15995481677,\n",
       " 2782.4579977408384,\n",
       " 1667.672899887042,\n",
       " 953.5836449943521,\n",
       " 1034.7291822497175,\n",
       " 1626.8364591124857,\n",
       " 460.3918229556243,\n",
       " 942.6195911477812,\n",
       " 628.5309795573891,\n",
       " 707.8265489778695,\n",
       " 537.9413274488935,\n",
       " 1466.1470663724447,\n",
       " 1397.6073533186222,\n",
       " 4940.5303676659305,\n",
       " 2552.6765183832968,\n",
       " 571.2838259191649,\n",
       " 411.41419129595823,\n",
       " 1318.270709564798,\n",
       " 973.16353547824,\n",
       " 4488.958176773912,\n",
       " 2902.4979088386954,\n",
       " 1475.124895441935,\n",
       " 716.9062447720968,\n",
       " 1188.1953122386049,\n",
       " 534.4097656119303,\n",
       " 777.2204882805966,\n",
       " 596.5110244140299,\n",
       " 900.0255512207015,\n",
       " 469.6512775610351,\n",
       " 324.63256387805177,\n",
       " 513.0816281939026,\n",
       " 448.40408140969515,\n",
       " 1237.4702040704847,\n",
       " 997.6235102035243,\n",
       " 614.1811755101762,\n",
       " 1481.3590587755086,\n",
       " 504.41795293877544,\n",
       " 739.6208976469388,\n",
       " 237.43104488234695,\n",
       " 1458.7215522441172,\n",
       " 432.9860776122059,\n",
       " 1553.04930388061,\n",
       " 1362.0524651940304,\n",
       " 793.9026232597015,\n",
       " 508.04513116298506,\n",
       " 508.00225655814927,\n",
       " 492.80011282790747,\n",
       " 630.7400056413954,\n",
       " 328.8870002820698,\n",
       " 482.8943500141035,\n",
       " 773.6947175007051,\n",
       " 1531.1347358750352,\n",
       " 878.3567367937518,\n",
       " 375.46783683968766,\n",
       " 1040.0233918419844,\n",
       " 1601.4511695920992,\n",
       " 1319.822558479605,\n",
       " 1414.9911279239802,\n",
       " 516.299556396199,\n",
       " 2101.56497781981,\n",
       " 496.4782488909906,\n",
       " 2212.6739124445494,\n",
       " 1268.6836956222276,\n",
       " 1084.6841847811115,\n",
       " 1444.0842092390556,\n",
       " 3095.1042104619523,\n",
       " 1360.3052105230977,\n",
       " 1415.1152605261548,\n",
       " 1431.1557630263076,\n",
       " 467.7077881513154,\n",
       " 641.8353894075657,\n",
       " 640.0917694703783,\n",
       " 366.4045884735189,\n",
       " 495.22022942367596,\n",
       " 693.5610114711837,\n",
       " 746.2280505735591,\n",
       " 1363.511402528678,\n",
       " 2329.1755701264337,\n",
       " 1263.1087785063216,\n",
       " 2713.655438925316,\n",
       " 925.1327719462658,\n",
       " 1439.9066385973133,\n",
       " 496.64533192986573,\n",
       " 2782.6822665964933,\n",
       " 802.2341133298248,\n",
       " 2866.361705666491,\n",
       " 2437.5680852833248,\n",
       " 2059.8784042641664,\n",
       " 1374.0939202132083,\n",
       " 924.6546960106604,\n",
       " 818.582734800533,\n",
       " 1056.4791367400267,\n",
       " 434.72395683700137,\n",
       " 812.13619784185,\n",
       " 854.7568098920925,\n",
       " 548.1378404946047,\n",
       " 392.2068920247302,\n",
       " 354.9603446012365,\n",
       " 793.8980172300618,\n",
       " 711.3449008615031,\n",
       " 576.1172450430752,\n",
       " 1532.6558622521536,\n",
       " 334.08279311260776,\n",
       " 792.8541396556304,\n",
       " 289.49270698278156,\n",
       " 1842.274635349139,\n",
       " 466.41373176745697,\n",
       " 1243.1206865883728,\n",
       " 985.5560343294187,\n",
       " 1427.727801716471,\n",
       " 519.7863900858235,\n",
       " 503.83931950429115,\n",
       " 483.0919659752146,\n",
       " 405.1045982987607,\n",
       " 165.60522991493804,\n",
       " 373.08026149574687,\n",
       " 289.4040130747874,\n",
       " 304.22020065373937,\n",
       " 253.66101003268696,\n",
       " 309.0830505016343,\n",
       " 425.8541525250817,\n",
       " 804.0927076262541,\n",
       " 1675.1546353813126,\n",
       " 1888.7577317690657,\n",
       " 558.0378865884534,\n",
       " 384.1518943294227,\n",
       " 197.80759471647116,\n",
       " 825.9403797358235,\n",
       " 407.9970189867912,\n",
       " 1281.0498509493395,\n",
       " 1153.7024925474668,\n",
       " 407.28512462737336,\n",
       " 674.9142562313687,\n",
       " 639.8457128115684,\n",
       " 200.14228564057845,\n",
       " 498.30711428202886,\n",
       " 517.0153557141015,\n",
       " 364.0507677857051,\n",
       " 329.80253838928525,\n",
       " 602.6401269194643,\n",
       " 256.2320063459732,\n",
       " 100.21160031729866,\n",
       " 764.0605800158648,\n",
       " 569.2530290007933,\n",
       " 299.2126514500397,\n",
       " 505.160632572502,\n",
       " 122.15803162862511,\n",
       " 1301.9079015814311,\n",
       " 183.8453950790716,\n",
       " 1632.7422697539535,\n",
       " 275.43711348769773,\n",
       " 322.5218556743849,\n",
       " 353.3760927837193,\n",
       " 1389.468804639186,\n",
       " 320.27344023195934,\n",
       " 313.36367201159794,\n",
       " 448.8681836005799,\n",
       " 241.893409180029,\n",
       " 273.34467045900146,\n",
       " 270.1672335229501,\n",
       " 50.55836167614751,\n",
       " 362.5779180838074,\n",
       " 209.07889590419038,\n",
       " 108.30394479520952,\n",
       " 465.2151972397604,\n",
       " 427.96075986198804,\n",
       " 237.99803799309942,\n",
       " 351.04990189965497,\n",
       " 111.60249509498276,\n",
       " 635.4301247547492,\n",
       " 136.2715062377375,\n",
       " 858.0135753118868,\n",
       " 188.2506787655944,\n",
       " 241.2125339382797,\n",
       " 201.11062669691398,\n",
       " 742.5055313348456,\n",
       " 309.77527656674226,\n",
       " 247.2887638283371,\n",
       " 297.36443819141687,\n",
       " 169.71822190957084,\n",
       " 167.13591109547855,\n",
       " 188.85679555477392,\n",
       " 63.5928397777387,\n",
       " 425.92964198888694,\n",
       " 159.99648209944436,\n",
       " 79.24982410497222,\n",
       " 717.4124912052486,\n",
       " 420.62062456026246,\n",
       " 208.18103122801313,\n",
       " 338.15905156140064,\n",
       " 111.90795257807005,\n",
       " 747.5453976289034,\n",
       " 122.8772698814452,\n",
       " 803.1938634940723,\n",
       " 147.50969317470364,\n",
       " 225.8754846587352,\n",
       " 217.44377423293673,\n",
       " 715.7721887116468,\n",
       " 274.23860943558236,\n",
       " 163.81193047177914,\n",
       " 245.69059652358897,\n",
       " 233.63452982617946,\n",
       " 155.13172649130897,\n",
       " 236.70658632456545,\n",
       " 73.58532931622828,\n",
       " 179.42926646581142,\n",
       " 54.57146332329057,\n",
       " 31.22857316616453,\n",
       " 167.81142865830822,\n",
       " 143.2905714329154,\n",
       " 67.96452857164577,\n",
       " 166.7982264285823,\n",
       " 35.88991132142912,\n",
       " 206.04449556607145,\n",
       " 40.70222477830358,\n",
       " 399.13511123891516,\n",
       " 78.85675556194577,\n",
       " 122.6928377780973,\n",
       " 98.28464188890486,\n",
       " 313.66423209444525,\n",
       " 99.28321160472227,\n",
       " 80.01416058023611,\n",
       " 85.7007080290118,\n",
       " 140.13503540145058,\n",
       " 31.706751770072536,\n",
       " 68.08533758850363,\n",
       " 15.754266879425185,\n",
       " 664.8377133439712,\n",
       " 291.64188566719855,\n",
       " 162.78209428335992,\n",
       " 770.0391047141679,\n",
       " 732.0019552357085,\n",
       " 418.5000977617854,\n",
       " 599.4750048880892,\n",
       " 189.5737502444045,\n",
       " 848.3286875122201,\n",
       " 178.26643437561103,\n",
       " 1206.8633217187805,\n",
       " 295.9431660859391,\n",
       " 451.79715830429694,\n",
       " 440.58985791521485,\n",
       " 1514.4794928957606,\n",
       " 460.4739746447881,\n",
       " 424.8736987322394,\n",
       " 322.393684936612,\n",
       " 356.2196842468306,\n",
       " 230.61098421234152,\n",
       " 331.6805492106171,\n",
       " 173.33402746053088,\n",
       " 388.66670137302657,\n",
       " 208.48333506865134,\n",
       " 151.97416675343257,\n",
       " 421.7987083376716,\n",
       " 448.5899354168836,\n",
       " 320.7294967708442,\n",
       " 372.28647483854223,\n",
       " 153.51432374192714,\n",
       " 750.5757161870963,\n",
       " 161.97878580935483,\n",
       " 829.8489392904678,\n",
       " 223.8924469645234,\n",
       " 244.89462234822616,\n",
       " 282.04473111741135,\n",
       " 863.4022365558706,\n",
       " 399.42011182779356,\n",
       " 397.1210055913897,\n",
       " 314.3560502795695,\n",
       " 206.66780251397847,\n",
       " 123.38339012569892,\n",
       " 182.86916950628495,\n",
       " 93.69345847531426,\n",
       " 589.8846729237656,\n",
       " 362.9442336461883,\n",
       " 195.79721168230944,\n",
       " 887.5898605841154,\n",
       " 824.3294930292058,\n",
       " 366.1164746514603,\n",
       " 591.155823732573,\n",
       " 183.4577911866287,\n",
       " 1513.9728895593314,\n",
       " 271.3986444779666,\n",
       " 1140.2699322238984,\n",
       " 352.46349661119496,\n",
       " 409.97317483055974,\n",
       " 505.948658741528,\n",
       " 1295.4474329370762,\n",
       " 594.8723716468539,\n",
       " 601.6436185823427,\n",
       " 434.78218092911715,\n",
       " 400.78910904645585,\n",
       " 264.18945545232276,\n",
       " 358.0594727726161,\n",
       " 187.0029736386308,\n",
       " 648.7001486819315,\n",
       " 290.8350074340966,\n",
       " 79.14175037170483,\n",
       " 663.2570875185852,\n",
       " 567.0628543759293,\n",
       " 371.3031427187965,\n",
       " 478.3651571359398,\n",
       " 81.86825785679702,\n",
       " 1241.9434128928397,\n",
       " 196.99717064464204,\n",
       " 1169.799858532232,\n",
       " 258.93999292661164,\n",
       " 288.4469996463306,\n",
       " 301.3223499823165,\n",
       " 1727.9161174991157,\n",
       " 344.7958058749558,\n",
       " 416.23979029374783,\n",
       " 340.0119895146874,\n",
       " 210.80059947573437,\n",
       " 206.2400299737867,\n",
       " 188.91200149868934,\n",
       " 73.09560007493448,\n",
       " 719.9547800037467,\n",
       " 1209.2477390001873,\n",
       " 257.1123869500094,\n",
       " 886.8556193475005,\n",
       " 1447.492780967375,\n",
       " 1972.3746390483689,\n",
       " 3480.6187319524183,\n",
       " 771.5809365976211,\n",
       " 5943.779046829881,\n",
       " 5042.438952341494,\n",
       " 2711.6719476170747,\n",
       " 1103.6335973808539,\n",
       " 1539.0816798690425,\n",
       " 6898.904083993452,\n",
       " 2111.945204199673,\n",
       " 1606.5972602099837,\n",
       " 1660.179863010499,\n",
       " 935.158993150525,\n",
       " 516.0579496575263,\n",
       " 733.5528974828763,\n",
       " 942.9776448741438,\n",
       " 497.4488822437072,\n",
       " 1287.4224441121853,\n",
       " 455.7711222056093,\n",
       " 816.9885561102805,\n",
       " 606.0994278055141,\n",
       " 1083.8549713902758,\n",
       " 696.3927485695137,\n",
       " 2114.3696374284755,\n",
       " 522.7684818714238,\n",
       " 391.8884240935712,\n",
       " 225.74442120467856,\n",
       " 2373.937221060234,\n",
       " 801.7468610530118,\n",
       " 1170.5873430526506,\n",
       " 1057.9293671526325,\n",
       " 1068.4464683576316,\n",
       " 502.7723234178816,\n",
       " 724.338616170894,\n",
       " 553.9669308085447,\n",
       " 231.94834654042725,\n",
       " 212.99741732702134,\n",
       " 1321.649870866351,\n",
       " 291.23249354331756,\n",
       " 383.16162467716583,\n",
       " 71.40808123385831,\n",
       " 45.370404061692916,\n",
       " 130.51852020308465,\n",
       " 120.52592601015424,\n",
       " 73.47629630050773,\n",
       " 211.72381481502538,\n",
       " 45.736190740751276,\n",
       " 121.98680953703756,\n",
       " 45.04934047685188,\n",
       " 254.0024670238426,\n",
       " 87.75012335119214,\n",
       " 117.4375061675596,\n",
       " 96.12187530837798,\n",
       " 143.50609376541888,\n",
       " 65.12530468827094,\n",
       " 123.90626523441354,\n",
       " 86.94531326172068,\n",
       " 41.39726566308603,\n",
       " 22.969863283154304,\n",
       " 74.2984931641577,\n",
       " 32.21492465820789,\n",
       " 328.4107462329104,\n",
       " 117.12053731164552,\n",
       " 125.55602686558227,\n",
       " 377.7278013432791,\n",
       " 655.386390067164,\n",
       " 307.31931950335826,\n",
       " 579.6659659751679,\n",
       " 239.8832982987584,\n",
       " 1591.844164914938,\n",
       " 461.49220824574695,\n",
       " 810.6246104122873,\n",
       " 302.7312305206144,\n",
       " 370.43656152603074,\n",
       " 286.42182807630155,\n",
       " 723.9710914038151,\n",
       " 650.8485545701908,\n",
       " 480.94242772850953,\n",
       " 567.4471213864255,\n",
       " 384.6223560693213,\n",
       " 327.0311178034661,\n",
       " 171.20155589017332,\n",
       " 108.31007779450867,\n",
       " 461.4155038897254,\n",
       " 456.2707751944863,\n",
       " 504.4635387597243,\n",
       " 907.7731769379861,\n",
       " 1244.2886588468991,\n",
       " 370.014432942345,\n",
       " 680.6507216471173,\n",
       " 300.98253608235586,\n",
       " 2343.4991268041176,\n",
       " 520.924956340206,\n",
       " 878.1962478170103,\n",
       " 356.4598123908506,\n",
       " 749.3229906195426,\n",
       " 572.3161495309772,\n",
       " 860.8158074765488,\n",
       " 1453.7907903738276,\n",
       " 809.8895395186914,\n",
       " 597.1944769759345,\n",
       " 768.0097238487967,\n",
       " 558.0504861924398,\n",
       " 640.652524309622,\n",
       " 409.1826262154811,\n",
       " 212.35913131077405,\n",
       " 204.4179565655387,\n",
       " 185.97089782827695,\n",
       " 179.34854489141384,\n",
       " 503.9174272445707,\n",
       " 348.19587136222856,\n",
       " 514.2597935681114,\n",
       " 232.8129896784056,\n",
       " 1387.2406494839202,\n",
       " 321.1120324741961,\n",
       " 676.3056016237098,\n",
       " 372.9652800811855,\n",
       " 351.1482640040593,\n",
       " 491.6074132002029,\n",
       " 682.9303706600102,\n",
       " 532.8965185330005,\n",
       " 471.24482592665004,\n",
       " 449.16224129633247,\n",
       " 465.15811206481663,\n",
       " 253.15790560324083,\n",
       " 171.30789528016206,\n",
       " 154.8653947640081,\n",
       " 348.7932697382004,\n",
       " 279.63966348691,\n",
       " 431.03198317434544,\n",
       " 315.1015991587173,\n",
       " 1046.5050799579358,\n",
       " 475.0752539978968,\n",
       " 2377.8537626998946,\n",
       " 811.4426881349948,\n",
       " 9001.92213440675,\n",
       " 1560.646106720338,\n",
       " 1730.0823053360168,\n",
       " 762.9041152668009,\n",
       " 1433.69520576334,\n",
       " 1641.084760288167,\n",
       " 818.3042380144084,\n",
       " 787.6152119007204,\n",
       " 1897.5807605950358,\n",
       " 1190.2290380297518,\n",
       " 2324.3114519014875,\n",
       " 321.4155725950745,\n",
       " 352.3707786297538,\n",
       " 558.1685389314877,\n",
       " 308.1584269465744,\n",
       " 406.8079213473287,\n",
       " 342.39039606736645,\n",
       " 531.0695198033683,\n",
       " 519.6034759901684,\n",
       " 481.98017379950846,\n",
       " 1157.4490086899752,\n",
       " 541.4224504344987,\n",
       " 3545.871122521725,\n",
       " 527.8435561260865,\n",
       " 1072.3421778063043,\n",
       " 524.8171088903152,\n",
       " 680.7908554445157,\n",
       " 1129.3895427722257,\n",
       " 925.7194771386113,\n",
       " 1566.2859738569307,\n",
       " 911.4642986928466,\n",
       " 854.0232149346423,\n",
       " 869.2011607467322,\n",
       " 310.4100580373366,\n",
       " 498.1205029018668,\n",
       " 574.9560251450933,\n",
       " 292.8478012572547,\n",
       " 291.09239006286276,\n",
       " 216.90461950314315,\n",
       " 267.34523097515716,\n",
       " 423.76726154875786,\n",
       " 409.73836307743784,\n",
       " 750.0869181538718,\n",
       " 322.5043459076936,\n",
       " 2603.9252172953843,\n",
       " 398.0962608647693,\n",
       " 1055.4048130432384,\n",
       " 347.270240652162,\n",
       " 434.4135120326081,\n",
       " 612.6206756016304,\n",
       " 855.2310337800815,\n",
       " 1084.911551689004,\n",
       " 583.3955775844502,\n",
       " 653.3197788792226,\n",
       " 425.9659889439611,\n",
       " 192.29829944719808,\n",
       " 348.76491497235986,\n",
       " 324.28824574861795,\n",
       " 249.9144122874309,\n",
       " 40.99572061437156,\n",
       " 20.09978603071858,\n",
       " 386.70498930153593,\n",
       " 75.38524946507681,\n",
       " 66.46926247325383,\n",
       " 332.0234631236627,\n",
       " 128.70117315618313,\n",
       " 1288.9350586578091,\n",
       " 99.59675293289052,\n",
       " 369.77983764664447,\n",
       " 67.88899188233223,\n",
       " 213.3444495941166,\n",
       " 192.11722247970582,\n",
       " 290.80586112398527,\n",
       " 76.29029305619927,\n",
       " 47.514514652809964,\n",
       " 93.57572573264049,\n",
       " 141.47878628663202,\n",
       " 26.073939314331607,\n",
       " 22.20369696571658,\n",
       " 79.01018484828582,\n",
       " 392.50050924241424,\n",
       " 380.62502546212073,\n",
       " 180.53125127310605,\n",
       " 393.7765625636553,\n",
       " 588.7388281281827,\n",
       " 571.886941406409,\n",
       " 679.3443470703205,\n",
       " 374.067217353516,\n",
       " 4940.6533608676755,\n",
       " 743.882668043384,\n",
       " 1208.544133402169,\n",
       " 528.7772066701085,\n",
       " 573.6388603335054,\n",
       " 646.1819430166753,\n",
       " 1328.1090971508338,\n",
       " 1296.6554548575418,\n",
       " 1035.7327727428772,\n",
       " 920.0866386371439,\n",
       " 455.4543319318572,\n",
       " 245.07271659659287,\n",
       " 184.20363582982964,\n",
       " 219.16018179149148,\n",
       " 352.0080090895746,\n",
       " 163.90040045447873,\n",
       " 244.74502002272393,\n",
       " 985.9872510011362,\n",
       " 501.49936255005684,\n",
       " 518.1249681275028,\n",
       " 1053.806248406375,\n",
       " 618.8903124203188,\n",
       " 3075.694515621016,\n",
       " 296.28472578105095,\n",
       " 1281.1642362890525,\n",
       " 368.05821181445265,\n",
       " 966.5029105907225,\n",
       " 755.1251455295361,\n",
       " 1445.6562572764767,\n",
       " 860.7828128638239,\n",
       " 900.8891406431911,\n",
       " 625.4944570321595,\n",
       " 1158.9247228516078,\n",
       " 315.39623614258045,\n",
       " 220.01981180712903,\n",
       " 598.1009905903564,\n",
       " 340.5550495295178,\n",
       " 90.1777524764759,\n",
       " 52.008887623823796,\n",
       " 508.9504443811912,\n",
       " 236.34752221905956,\n",
       " 123.91737611095299,\n",
       " 206.64586880554765,\n",
       " 50.23229344027739,\n",
       " 295.11161467201384,\n",
       " 58.4555807336007,\n",
       " 198.62277903668001,\n",
       " 71.68113895183401,\n",
       " 105.2340569475917,\n",
       " 180.06170284737956,\n",
       " 136.30308514236899,\n",
       " 119.86515425711845,\n",
       " 173.1932577128559,\n",
       " 127.4096628856428,\n",
       " 80.47048314428214,\n",
       " 100.9235241572141,\n",
       " 172.24617620786069,\n",
       " 56.112308810393046,\n",
       " 296.35561544051967,\n",
       " 296.96778077202595,\n",
       " 220.0483890386013,\n",
       " 404.30241945193,\n",
       " 674.7651209725965,\n",
       " 937.1882560486298,\n",
       " 1046.2594128024316,\n",
       " 346.81297064012165,\n",
       " 910.3406485320061,\n",
       " 316.26703242660034,\n",
       " 1221.36335162133,\n",
       " 642.4681675810665,\n",
       " 815.8734083790533,\n",
       " 1270.0936704189526,\n",
       " 1442.9046835209476,\n",
       " 596.5452341760474,\n",
       " 536.1772617088023,\n",
       " 381.1588630854401,\n",
       " 250.857943154272,\n",
       " 137.94289715771362,\n",
       " 323.24714485788564,\n",
       " 166.2623572428943,\n",
       " 165.06311786214474,\n",
       " 486.1031558931072,\n",
       " 271.3051577946554,\n",
       " 564.5652578897328,\n",
       " 775.8782628944866,\n",
       " 954.5939131447243,\n",
       " 962.5796956572361,\n",
       " 272.3289847828618,\n",
       " 545.6164492391431,\n",
       " 201.13082246195717,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpprice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     532.833310\n",
       "1     469.341666\n",
       "2     267.617083\n",
       "3     400.980854\n",
       "4     599.549043\n",
       "5     225.677452\n",
       "6     489.133873\n",
       "7     248.656694\n",
       "8    3465.682835\n",
       "9     600.784142\n",
       "Name: salesVolume, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['salesVolume'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "Name: salesVolume, dtype: bool"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为new_xgb保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_old=pd.read_csv('./middle_rst.csv')\n",
    "data_df_old[features].to_csv('./middle_rst_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    #mask=~data['salesVolume'].isnull()\n",
    "    #data['salesVolume'][mask] = exponential_smoothing(data['salesVolume'][mask],0.95)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    data.to_csv('original_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                bagging_fraction=0.58,num_leaves=127,num_trees=527,\n",
    "                                max_depth=5,learning_rate=0.0511,n_estimators=8679,\n",
    "                                objective='reg:gamma',tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7,min_child_samples=6,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 8309.82\tvalid_1's l2: 50784.8\n",
      "[200]\ttraining's l2: 4524.09\tvalid_1's l2: 47517.7\n",
      "[300]\ttraining's l2: 3121.02\tvalid_1's l2: 46722.2\n",
      "[400]\ttraining's l2: 2261.11\tvalid_1's l2: 45954.5\n",
      "[500]\ttraining's l2: 1788.28\tvalid_1's l2: 45656.2\n",
      "[600]\ttraining's l2: 1442.11\tvalid_1's l2: 45398.4\n",
      "[700]\ttraining's l2: 1177.82\tvalid_1's l2: 45271.1\n",
      "[800]\ttraining's l2: 974.946\tvalid_1's l2: 45068.9\n",
      "[900]\ttraining's l2: 823.477\tvalid_1's l2: 45055.5\n",
      "Early stopping, best iteration is:\n",
      "[828]\ttraining's l2: 927.752\tvalid_1's l2: 45039.4\n",
      "0.7189541796021575\n",
      "valid mean: 490.3871820360307\n",
      "true  mean: 559.0532150776053\n",
      "test  mean: 490.1664339729076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 8653.88\tvalid_1's l2: 63392.8\n",
      "[200]\ttraining's l2: 4744.69\tvalid_1's l2: 60506.5\n",
      "[300]\ttraining's l2: 3402.46\tvalid_1's l2: 59542\n",
      "[400]\ttraining's l2: 2580.75\tvalid_1's l2: 58958.2\n",
      "[500]\ttraining's l2: 2061.37\tvalid_1's l2: 58827.6\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttraining's l2: 2100.58\tvalid_1's l2: 58727.1\n",
      "0.6716090665954307\n",
      "valid mean: 465.393969897045\n",
      "true  mean: 531.319290465632\n",
      "test  mean: 351.98349570504763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 9879.59\tvalid_1's l2: 62845.8\n",
      "[200]\ttraining's l2: 5476.27\tvalid_1's l2: 57839.9\n",
      "[300]\ttraining's l2: 3892.06\tvalid_1's l2: 57434.2\n",
      "[400]\ttraining's l2: 2950.35\tvalid_1's l2: 57096.5\n",
      "[500]\ttraining's l2: 2353.28\tvalid_1's l2: 56798.9\n",
      "[600]\ttraining's l2: 1920.32\tvalid_1's l2: 56673.4\n",
      "[700]\ttraining's l2: 1602.34\tvalid_1's l2: 56757.5\n",
      "Early stopping, best iteration is:\n",
      "[613]\ttraining's l2: 1870.6\tvalid_1's l2: 56647.9\n",
      "0.7062427177346114\n",
      "valid mean: 478.71703367452415\n",
      "true  mean: 577.2344789356985\n",
      "test  mean: 485.7528446871517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 10185\tvalid_1's l2: 194624\n",
      "[200]\ttraining's l2: 5905.16\tvalid_1's l2: 184138\n",
      "[300]\ttraining's l2: 4160.35\tvalid_1's l2: 181575\n",
      "[400]\ttraining's l2: 3194.96\tvalid_1's l2: 180172\n",
      "[500]\ttraining's l2: 2606.81\tvalid_1's l2: 179475\n",
      "[600]\ttraining's l2: 2122.77\tvalid_1's l2: 178825\n",
      "[700]\ttraining's l2: 1798.56\tvalid_1's l2: 178431\n",
      "[800]\ttraining's l2: 1536.8\tvalid_1's l2: 178093\n",
      "[900]\ttraining's l2: 1344.6\tvalid_1's l2: 177870\n",
      "[1000]\ttraining's l2: 1146.65\tvalid_1's l2: 177603\n",
      "[1100]\ttraining's l2: 1005.4\tvalid_1's l2: 177455\n",
      "[1200]\ttraining's l2: 889.179\tvalid_1's l2: 177099\n",
      "[1300]\ttraining's l2: 789.104\tvalid_1's l2: 177057\n",
      "[1400]\ttraining's l2: 707.078\tvalid_1's l2: 176992\n",
      "[1500]\ttraining's l2: 631.296\tvalid_1's l2: 177007\n",
      "[1600]\ttraining's l2: 567.262\tvalid_1's l2: 176927\n",
      "[1700]\ttraining's l2: 512.983\tvalid_1's l2: 176942\n",
      "[1800]\ttraining's l2: 465.501\tvalid_1's l2: 176908\n",
      "[1900]\ttraining's l2: 421.588\tvalid_1's l2: 176866\n",
      "[2000]\ttraining's l2: 381.814\tvalid_1's l2: 176819\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's l2: 381.814\tvalid_1's l2: 176819\n",
      "0.5645389005410395\n",
      "valid mean: 527.1291286657715\n",
      "true  mean: 769.5532150776053\n",
      "test  mean: 467.7141008653344\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    #mask=~data['salesVolume'].isnull()\n",
    "    #data['salesVolume'][mask] = exponential_smoothing(data['salesVolume'][mask],0.95)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'lgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_lgb_tiaocan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去异常值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']\n",
    "\n",
    "def quantile_clip(group):\n",
    "    #group.plot()\n",
    "    group[group < group.quantile(.05)] = group.quantile(.05)\n",
    "    group[group > group.quantile(.95)] = group.quantile(.95)\n",
    "    #group.plot()\n",
    "    #plt.show()\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.93it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:757.617\tvalidation_1-rmse:931.125\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:718.08\tvalidation_1-rmse:891.171\n",
      "[200]\tvalidation_0-rmse:229.523\tvalidation_1-rmse:365.122\n",
      "[300]\tvalidation_0-rmse:124.108\tvalidation_1-rmse:252.668\n",
      "[400]\tvalidation_0-rmse:107.776\tvalidation_1-rmse:243.108\n",
      "[500]\tvalidation_0-rmse:100.375\tvalidation_1-rmse:238.056\n",
      "[600]\tvalidation_0-rmse:94.4662\tvalidation_1-rmse:234.209\n",
      "[700]\tvalidation_0-rmse:88.8747\tvalidation_1-rmse:231.041\n",
      "[800]\tvalidation_0-rmse:83.6664\tvalidation_1-rmse:228.863\n",
      "[900]\tvalidation_0-rmse:79.7014\tvalidation_1-rmse:225.99\n",
      "[1000]\tvalidation_0-rmse:75.7866\tvalidation_1-rmse:224.489\n",
      "[1100]\tvalidation_0-rmse:71.9663\tvalidation_1-rmse:223.368\n",
      "[1200]\tvalidation_0-rmse:68.4655\tvalidation_1-rmse:223.076\n",
      "Stopping. Best iteration:\n",
      "[1194]\tvalidation_0-rmse:68.6601\tvalidation_1-rmse:222.943\n",
      "\n",
      "0.7683027711710365\n",
      "valid mean: 512.4066772460938\n",
      "true  mean: 556.6262195121955\n",
      "test  mean: 461.3200988769531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 26.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:778.807\tvalidation_1-rmse:898.617\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:739.264\tvalidation_1-rmse:859.909\n",
      "[200]\tvalidation_0-rmse:235.811\tvalidation_1-rmse:423.555\n",
      "[300]\tvalidation_0-rmse:123.719\tvalidation_1-rmse:357.222\n",
      "[400]\tvalidation_0-rmse:112.581\tvalidation_1-rmse:351.103\n",
      "[500]\tvalidation_0-rmse:105.382\tvalidation_1-rmse:350.471\n",
      "Stopping. Best iteration:\n",
      "[436]\tvalidation_0-rmse:109.313\tvalidation_1-rmse:349.817\n",
      "\n",
      "0.5938173711118979\n",
      "valid mean: 380.1831970214844\n",
      "true  mean: 531.6218680709541\n",
      "test  mean: 356.3283386230469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 24.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:791.604\tvalidation_1-rmse:956.125\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:752.093\tvalidation_1-rmse:916.346\n",
      "[200]\tvalidation_0-rmse:244.98\tvalidation_1-rmse:427.263\n",
      "[300]\tvalidation_0-rmse:130.936\tvalidation_1-rmse:334.986\n",
      "[400]\tvalidation_0-rmse:115.848\tvalidation_1-rmse:329.047\n",
      "[500]\tvalidation_0-rmse:107.751\tvalidation_1-rmse:325.475\n",
      "[600]\tvalidation_0-rmse:101.715\tvalidation_1-rmse:323.231\n",
      "[700]\tvalidation_0-rmse:98.2076\tvalidation_1-rmse:321.05\n",
      "[800]\tvalidation_0-rmse:93.8661\tvalidation_1-rmse:320.444\n",
      "[900]\tvalidation_0-rmse:89.82\tvalidation_1-rmse:320.186\n",
      "[1000]\tvalidation_0-rmse:86.3518\tvalidation_1-rmse:320.719\n",
      "Stopping. Best iteration:\n",
      "[913]\tvalidation_0-rmse:89.2528\tvalidation_1-rmse:319.882\n",
      "\n",
      "0.6508045630795574\n",
      "valid mean: 443.1093444824219\n",
      "true  mean: 576.4874168514414\n",
      "test  mean: 318.73773193359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.72it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 26.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:807.946\tvalidation_1-rmse:1189.55\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:768.364\tvalidation_1-rmse:1148.69\n",
      "[200]\tvalidation_0-rmse:252.186\tvalidation_1-rmse:606.758\n",
      "[300]\tvalidation_0-rmse:134.437\tvalidation_1-rmse:536.715\n",
      "Stopping. Best iteration:\n",
      "[274]\tvalidation_0-rmse:141.189\tvalidation_1-rmse:532.994\n",
      "\n",
      "0.40847847763405454\n",
      "valid mean: 395.0877990722656\n",
      "true  mean: 719.7307926829268\n",
      "test  mean: 285.6610107421875\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    data['salesVolume'] = data.groupby(['adcode', 'model'])['salesVolume'].transform(quantile_clip)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'xgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_xgb_abnormal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 26.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:756.046\tvalidation_1-rmse:934.136\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:716.706\tvalidation_1-rmse:894.206\n",
      "[200]\tvalidation_0-rmse:233.236\tvalidation_1-rmse:366.55\n",
      "[300]\tvalidation_0-rmse:121.341\tvalidation_1-rmse:237.091\n",
      "[400]\tvalidation_0-rmse:104.028\tvalidation_1-rmse:225.787\n",
      "[500]\tvalidation_0-rmse:95.5082\tvalidation_1-rmse:226.834\n",
      "Stopping. Best iteration:\n",
      "[407]\tvalidation_0-rmse:103.426\tvalidation_1-rmse:225.111\n",
      "\n",
      "0.7538564197390623\n",
      "valid mean: 501.8374938964844\n",
      "true  mean: 559.0532150776053\n",
      "test  mean: 461.4864501953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 27.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:777.85\tvalidation_1-rmse:898.685\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:738.473\tvalidation_1-rmse:860.178\n",
      "[200]\tvalidation_0-rmse:240.043\tvalidation_1-rmse:453.467\n",
      "[300]\tvalidation_0-rmse:126.359\tvalidation_1-rmse:398.044\n",
      "Stopping. Best iteration:\n",
      "[283]\tvalidation_0-rmse:132.573\tvalidation_1-rmse:395.611\n",
      "\n",
      "0.5687436258401762\n",
      "valid mean: 370.1124572753906\n",
      "true  mean: 531.319290465632\n",
      "test  mean: 280.6367492675781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 26.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:790.765\tvalidation_1-rmse:957.098\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:751.406\tvalidation_1-rmse:917.475\n",
      "[200]\tvalidation_0-rmse:250.605\tvalidation_1-rmse:418.734\n",
      "[300]\tvalidation_0-rmse:137.449\tvalidation_1-rmse:298.219\n",
      "[400]\tvalidation_0-rmse:120.178\tvalidation_1-rmse:289.474\n",
      "[500]\tvalidation_0-rmse:108.515\tvalidation_1-rmse:286.026\n",
      "[600]\tvalidation_0-rmse:101.124\tvalidation_1-rmse:287.188\n",
      "Stopping. Best iteration:\n",
      "[556]\tvalidation_0-rmse:104.118\tvalidation_1-rmse:284.691\n",
      "\n",
      "0.6928770654964207\n",
      "valid mean: 459.1951599121094\n",
      "true  mean: 577.2344789356985\n",
      "test  mean: 291.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 26.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:807.303\tvalidation_1-rmse:1292.89\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:767.859\tvalidation_1-rmse:1252.75\n",
      "[200]\tvalidation_0-rmse:257.339\tvalidation_1-rmse:727.719\n",
      "[300]\tvalidation_0-rmse:133.302\tvalidation_1-rmse:664.588\n",
      "Stopping. Best iteration:\n",
      "[227]\tvalidation_0-rmse:176.042\tvalidation_1-rmse:661.768\n",
      "\n",
      "0.35097409977608596\n",
      "valid mean: 382.886962890625\n",
      "true  mean: 769.5532150776053\n",
      "test  mean: 273.4256896972656\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    #mask=~data['salesVolume'].isnull()\n",
    "    #data['salesVolume'][mask] = exponential_smoothing(data['salesVolume'][mask],0.95)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['model', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['model', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'xgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_model_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# area_sales&model_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume', 'model_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 22.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:756.046\tvalidation_1-rmse:934.136\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:716.709\tvalidation_1-rmse:894.329\n",
      "[200]\tvalidation_0-rmse:233.675\tvalidation_1-rmse:389.818\n",
      "[300]\tvalidation_0-rmse:123.913\tvalidation_1-rmse:289.517\n",
      "[400]\tvalidation_0-rmse:105.543\tvalidation_1-rmse:277.879\n",
      "[500]\tvalidation_0-rmse:95.2349\tvalidation_1-rmse:273.872\n",
      "[600]\tvalidation_0-rmse:86.256\tvalidation_1-rmse:269.975\n",
      "[700]\tvalidation_0-rmse:80.3876\tvalidation_1-rmse:267.794\n",
      "[800]\tvalidation_0-rmse:75.7549\tvalidation_1-rmse:265.475\n",
      "[900]\tvalidation_0-rmse:71.9827\tvalidation_1-rmse:266.068\n",
      "Stopping. Best iteration:\n",
      "[816]\tvalidation_0-rmse:75.0684\tvalidation_1-rmse:265.045\n",
      "\n",
      "0.7417953529701986\n",
      "valid mean: 488.8229064941406\n",
      "true  mean: 559.0532150776053\n",
      "test  mean: 469.5141296386719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 24.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:777.85\tvalidation_1-rmse:898.685\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:738.477\tvalidation_1-rmse:860.275\n",
      "[200]\tvalidation_0-rmse:239.929\tvalidation_1-rmse:451.203\n",
      "[300]\tvalidation_0-rmse:125.964\tvalidation_1-rmse:386.132\n",
      "[400]\tvalidation_0-rmse:107.577\tvalidation_1-rmse:385.179\n",
      "[500]\tvalidation_0-rmse:97.5323\tvalidation_1-rmse:384.702\n",
      "Stopping. Best iteration:\n",
      "[458]\tvalidation_0-rmse:101.331\tvalidation_1-rmse:384.231\n",
      "\n",
      "0.5685182210206637\n",
      "valid mean: 367.9149169921875\n",
      "true  mean: 531.319290465632\n",
      "test  mean: 286.6864318847656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 23.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:790.765\tvalidation_1-rmse:957.098\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:751.409\tvalidation_1-rmse:917.38\n",
      "[200]\tvalidation_0-rmse:248.649\tvalidation_1-rmse:434.082\n",
      "[300]\tvalidation_0-rmse:132.976\tvalidation_1-rmse:346.697\n",
      "[400]\tvalidation_0-rmse:113.165\tvalidation_1-rmse:341.257\n",
      "[500]\tvalidation_0-rmse:101.661\tvalidation_1-rmse:339.11\n",
      "[600]\tvalidation_0-rmse:94.0367\tvalidation_1-rmse:339.573\n",
      "Stopping. Best iteration:\n",
      "[509]\tvalidation_0-rmse:100.833\tvalidation_1-rmse:338.667\n",
      "\n",
      "0.6631120802468129\n",
      "valid mean: 432.3575134277344\n",
      "true  mean: 577.2344789356985\n",
      "test  mean: 281.7676086425781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 24.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:807.303\tvalidation_1-rmse:1292.89\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:767.862\tvalidation_1-rmse:1252.77\n",
      "[200]\tvalidation_0-rmse:255.167\tvalidation_1-rmse:721.513\n",
      "[300]\tvalidation_0-rmse:133.44\tvalidation_1-rmse:637.152\n",
      "[400]\tvalidation_0-rmse:115.09\tvalidation_1-rmse:633.112\n",
      "[500]\tvalidation_0-rmse:103.399\tvalidation_1-rmse:631.293\n",
      "[600]\tvalidation_0-rmse:96.5808\tvalidation_1-rmse:629.917\n",
      "[700]\tvalidation_0-rmse:90.4574\tvalidation_1-rmse:631.398\n",
      "Stopping. Best iteration:\n",
      "[668]\tvalidation_0-rmse:92.0926\tvalidation_1-rmse:629.337\n",
      "\n",
      "0.38084102185024893\n",
      "valid mean: 401.1592712402344\n",
      "true  mean: 769.5532150776053\n",
      "test  mean: 262.2773132324219\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    #mask=~data['salesVolume'].isnull()\n",
    "    #data['salesVolume'][mask] = exponential_smoothing(data['salesVolume'][mask],0.95)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "    \n",
    "    model_sales = {}\n",
    "    for raw in data[['model', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if model_sales.__contains__(key):\n",
    "            model_sales[key] += sales\n",
    "        else:\n",
    "            model_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['model', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(model_sales[key])\n",
    "        new_column1.append(sales/model_sales[key])\n",
    "    data['model_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'xgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_area_model_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'ctb':\n",
    "        model = CatBoostRegressor(iterations=250,\n",
    "                                 learning_rate=0.05,\n",
    "                                 depth=10,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 random_seed = 42,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 od_type='Iter',\n",
    "                                 metric_period = 50,\n",
    "                                 od_wait=20)\n",
    "        model.fit(train_x, train_y,\n",
    "                  cat_features=cate_feat,\n",
    "                  eval_set=(valid_x, valid_y),\n",
    "                  use_best_model=True,\n",
    "                  verbose=True)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    elif m_type == 'ctb':\n",
    "        #model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], cat_features=cate_feat)\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 582.9760460\ttest: 734.7351976\tbest: 734.7351976 (0)\ttotal: 145ms\tremaining: 36s\n",
      "50:\tlearn: 173.3949164\ttest: 359.2651602\tbest: 359.2651602 (50)\ttotal: 4.42s\tremaining: 17.3s\n",
      "100:\tlearn: 129.2509500\ttest: 329.7306158\tbest: 329.6868145 (99)\ttotal: 8.61s\tremaining: 12.7s\n",
      "150:\tlearn: 111.1436697\ttest: 316.7218825\tbest: 316.7218825 (150)\ttotal: 12.8s\tremaining: 8.4s\n",
      "200:\tlearn: 99.6286812\ttest: 311.6190871\tbest: 311.6190871 (200)\ttotal: 17s\tremaining: 4.14s\n",
      "249:\tlearn: 90.5104003\ttest: 310.2387810\tbest: 310.2387810 (249)\ttotal: 21.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 310.238781\n",
      "bestIteration = 249\n",
      "\n",
      "0.6840336497059338\n",
      "0:\tlearn: 667.3371076\ttotal: 101ms\tremaining: 25s\n",
      "50:\tlearn: 205.2793746\ttotal: 4.8s\tremaining: 18.7s\n",
      "100:\tlearn: 155.0376196\ttotal: 9.55s\tremaining: 14.1s\n",
      "150:\tlearn: 137.6242529\ttotal: 14.2s\tremaining: 9.34s\n",
      "200:\tlearn: 125.9528792\ttotal: 19.1s\tremaining: 4.65s\n",
      "249:\tlearn: 117.0525871\ttotal: 23.9s\tremaining: 0us\n",
      "valid mean: 462.45061324238145\n",
      "true  mean: 559.0532150776053\n",
      "test  mean: 500.64068177486644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric is calculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 599.8632954\ttest: 707.1474115\tbest: 707.1474115 (0)\ttotal: 95ms\tremaining: 23.7s\n",
      "50:\tlearn: 173.3080054\ttest: 384.7781387\tbest: 384.7781387 (50)\ttotal: 4.63s\tremaining: 18.1s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    #mask=~data['salesVolume'].isnull()\n",
    "    #data['salesVolume'][mask] = exponential_smoothing(data['salesVolume'][mask],0.95)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'ctb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "        elif m_type == 'ctb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_cat_car_prediction_sales.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgb+abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']\n",
    "def quantile_clip(group):\n",
    "    #group.plot()\n",
    "    group[group < group.quantile(.05)] = group.quantile(.05)\n",
    "    group[group > group.quantile(.95)] = group.quantile(.95)\n",
    "    #group.plot()\n",
    "    #plt.show()\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 7773.44\tvalid_1's l2: 40836.7\n",
      "[200]\ttraining's l2: 4167.36\tvalid_1's l2: 37648.5\n",
      "[300]\ttraining's l2: 2851.13\tvalid_1's l2: 36708.2\n",
      "[400]\ttraining's l2: 2118.29\tvalid_1's l2: 36228.3\n",
      "[500]\ttraining's l2: 1634.66\tvalid_1's l2: 35964.7\n",
      "[600]\ttraining's l2: 1330.14\tvalid_1's l2: 35773.2\n",
      "[700]\ttraining's l2: 1091.04\tvalid_1's l2: 35770.9\n",
      "[800]\ttraining's l2: 903.396\tvalid_1's l2: 35687.8\n",
      "[900]\ttraining's l2: 763.602\tvalid_1's l2: 35588.6\n",
      "Early stopping, best iteration is:\n",
      "[880]\ttraining's l2: 788.617\tvalid_1's l2: 35583\n",
      "0.7269185701756633\n",
      "valid mean: 477.82292290364705\n",
      "true  mean: 556.6262195121955\n",
      "test  mean: 493.7830262177206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 8009.68\tvalid_1's l2: 65741.6\n",
      "[200]\ttraining's l2: 4459.18\tvalid_1's l2: 63086.7\n",
      "[300]\ttraining's l2: 3227.4\tvalid_1's l2: 62356.3\n",
      "[400]\ttraining's l2: 2399.48\tvalid_1's l2: 61795.4\n",
      "[500]\ttraining's l2: 1886.05\tvalid_1's l2: 61964.8\n",
      "Early stopping, best iteration is:\n",
      "[410]\ttraining's l2: 2336.22\tvalid_1's l2: 61759.7\n",
      "0.6923002828429897\n",
      "valid mean: 472.22941153739583\n",
      "true  mean: 531.6218680709541\n",
      "test  mean: 350.65750731980637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 9202.31\tvalid_1's l2: 68055\n",
      "[200]\ttraining's l2: 5077.15\tvalid_1's l2: 63724.3\n",
      "[300]\ttraining's l2: 3624.83\tvalid_1's l2: 62794.4\n",
      "[400]\ttraining's l2: 2738.63\tvalid_1's l2: 62678.1\n",
      "Early stopping, best iteration is:\n",
      "[356]\ttraining's l2: 3092.65\tvalid_1's l2: 62526.1\n",
      "0.7196731877424329\n",
      "valid mean: 484.4388083229382\n",
      "true  mean: 576.4874168514414\n",
      "test  mean: 487.60449235983504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 9551.76\tvalid_1's l2: 107199\n",
      "[200]\ttraining's l2: 5504.08\tvalid_1's l2: 100623\n",
      "[300]\ttraining's l2: 3894.6\tvalid_1's l2: 98426.4\n",
      "[400]\ttraining's l2: 3002.51\tvalid_1's l2: 98027.6\n",
      "[500]\ttraining's l2: 2441.45\tvalid_1's l2: 97732.2\n",
      "Early stopping, best iteration is:\n",
      "[497]\ttraining's l2: 2455.98\tvalid_1's l2: 97727.2\n",
      "0.613942784638706\n",
      "valid mean: 523.592314687327\n",
      "true  mean: 719.7307926829268\n",
      "test  mean: 487.8328066197992\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    data['salesVolume'] = data.groupby(['adcode', 'model'])['salesVolume'].transform(quantile_clip)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'lgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_lgb_areaSale_abnormal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgb+model sale+abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']\n",
    "def quantile_clip(group):\n",
    "    #group.plot()\n",
    "    group[group < group.quantile(.05)] = group.quantile(.05)\n",
    "    group[group > group.quantile(.95)] = group.quantile(.95)\n",
    "    #group.plot()\n",
    "    #plt.show()\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 7806.64\tvalid_1's l2: 31541.9\n",
      "[200]\ttraining's l2: 4033.63\tvalid_1's l2: 27632.1\n",
      "[300]\ttraining's l2: 2805.65\tvalid_1's l2: 27381.2\n",
      "[400]\ttraining's l2: 2052.03\tvalid_1's l2: 27276.9\n",
      "[500]\ttraining's l2: 1592.2\tvalid_1's l2: 27251.3\n",
      "[600]\ttraining's l2: 1286.5\tvalid_1's l2: 27175.1\n",
      "[700]\ttraining's l2: 1061.27\tvalid_1's l2: 27224.1\n",
      "Early stopping, best iteration is:\n",
      "[616]\ttraining's l2: 1243.98\tvalid_1's l2: 27135.8\n",
      "0.7441883782427814\n",
      "valid mean: 488.53109678322113\n",
      "true  mean: 556.6262195121955\n",
      "test  mean: 487.7110367813596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 7959.01\tvalid_1's l2: 57823.4\n",
      "[200]\ttraining's l2: 4290.25\tvalid_1's l2: 55260.8\n",
      "[300]\ttraining's l2: 3035.35\tvalid_1's l2: 54483.7\n",
      "[400]\ttraining's l2: 2316.93\tvalid_1's l2: 54331.3\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's l2: 2371.58\tvalid_1's l2: 54322.8\n",
      "0.7166771624346866\n",
      "valid mean: 482.10188124434563\n",
      "true  mean: 531.6218680709541\n",
      "test  mean: 331.93550951531665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 8820.31\tvalid_1's l2: 55799.8\n",
      "[200]\ttraining's l2: 4928.44\tvalid_1's l2: 53035.7\n",
      "[300]\ttraining's l2: 3457.39\tvalid_1's l2: 52620.7\n",
      "[400]\ttraining's l2: 2649.33\tvalid_1's l2: 52353.5\n",
      "[500]\ttraining's l2: 2117.74\tvalid_1's l2: 52255.1\n",
      "Early stopping, best iteration is:\n",
      "[420]\ttraining's l2: 2535.46\tvalid_1's l2: 52183.5\n",
      "0.7367270153834871\n",
      "valid mean: 487.65161699093915\n",
      "true  mean: 576.4874168514414\n",
      "test  mean: 463.87019116875126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l2: 9176.6\tvalid_1's l2: 125075\n",
      "[200]\ttraining's l2: 5121.08\tvalid_1's l2: 118001\n",
      "[300]\ttraining's l2: 3638.31\tvalid_1's l2: 116718\n",
      "[400]\ttraining's l2: 2813.51\tvalid_1's l2: 115893\n",
      "[500]\ttraining's l2: 2264.39\tvalid_1's l2: 115771\n",
      "[600]\ttraining's l2: 1866.7\tvalid_1's l2: 115730\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttraining's l2: 2030.75\tvalid_1's l2: 115650\n",
      "0.6380907009838253\n",
      "valid mean: 529.961575920203\n",
      "true  mean: 719.7307926829268\n",
      "test  mean: 463.7539452157097\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    data['salesVolume'] = data.groupby(['adcode', 'model'])['salesVolume'].transform(quantile_clip)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['model', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['model', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'lgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_lgb_modelSale_abnormal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb+areaSale+abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:757.617\tvalidation_1-rmse:931.125\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:718.08\tvalidation_1-rmse:891.171\n",
      "[200]\tvalidation_0-rmse:229.523\tvalidation_1-rmse:365.122\n",
      "[300]\tvalidation_0-rmse:124.108\tvalidation_1-rmse:252.668\n",
      "[400]\tvalidation_0-rmse:107.776\tvalidation_1-rmse:243.108\n",
      "[500]\tvalidation_0-rmse:100.375\tvalidation_1-rmse:238.056\n",
      "[600]\tvalidation_0-rmse:94.4662\tvalidation_1-rmse:234.209\n",
      "[700]\tvalidation_0-rmse:88.8747\tvalidation_1-rmse:231.041\n",
      "[800]\tvalidation_0-rmse:83.6664\tvalidation_1-rmse:228.863\n",
      "[900]\tvalidation_0-rmse:79.7014\tvalidation_1-rmse:225.99\n",
      "[1000]\tvalidation_0-rmse:75.7866\tvalidation_1-rmse:224.489\n",
      "[1100]\tvalidation_0-rmse:71.9663\tvalidation_1-rmse:223.368\n",
      "[1200]\tvalidation_0-rmse:68.4655\tvalidation_1-rmse:223.076\n",
      "Stopping. Best iteration:\n",
      "[1194]\tvalidation_0-rmse:68.6601\tvalidation_1-rmse:222.943\n",
      "\n",
      "0.7683027711710365\n",
      "valid mean: 512.4066772460938\n",
      "true  mean: 556.6262195121955\n",
      "test  mean: 461.3200988769531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.99it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 25.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:778.807\tvalidation_1-rmse:898.617\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:739.264\tvalidation_1-rmse:859.909\n",
      "[200]\tvalidation_0-rmse:235.811\tvalidation_1-rmse:423.555\n",
      "[300]\tvalidation_0-rmse:123.719\tvalidation_1-rmse:357.222\n",
      "[400]\tvalidation_0-rmse:112.581\tvalidation_1-rmse:351.103\n",
      "[500]\tvalidation_0-rmse:105.382\tvalidation_1-rmse:350.471\n",
      "Stopping. Best iteration:\n",
      "[436]\tvalidation_0-rmse:109.313\tvalidation_1-rmse:349.817\n",
      "\n",
      "0.5938173711118979\n",
      "valid mean: 380.1831970214844\n",
      "true  mean: 531.6218680709541\n",
      "test  mean: 356.3283386230469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  3.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 25.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:791.604\tvalidation_1-rmse:956.125\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:752.093\tvalidation_1-rmse:916.346\n",
      "[200]\tvalidation_0-rmse:244.98\tvalidation_1-rmse:427.263\n",
      "[300]\tvalidation_0-rmse:130.936\tvalidation_1-rmse:334.986\n",
      "[400]\tvalidation_0-rmse:115.848\tvalidation_1-rmse:329.047\n",
      "[500]\tvalidation_0-rmse:107.751\tvalidation_1-rmse:325.475\n",
      "[600]\tvalidation_0-rmse:101.715\tvalidation_1-rmse:323.231\n",
      "[700]\tvalidation_0-rmse:98.2076\tvalidation_1-rmse:321.05\n",
      "[800]\tvalidation_0-rmse:93.8661\tvalidation_1-rmse:320.444\n",
      "[900]\tvalidation_0-rmse:89.82\tvalidation_1-rmse:320.186\n",
      "[1000]\tvalidation_0-rmse:86.3518\tvalidation_1-rmse:320.719\n",
      "Stopping. Best iteration:\n",
      "[913]\tvalidation_0-rmse:89.2528\tvalidation_1-rmse:319.882\n",
      "\n",
      "0.6508045630795574\n",
      "valid mean: 443.1093444824219\n",
      "true  mean: 576.4874168514414\n",
      "test  mean: 318.73773193359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 25.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:807.946\tvalidation_1-rmse:1189.55\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:768.364\tvalidation_1-rmse:1148.69\n",
      "[200]\tvalidation_0-rmse:252.186\tvalidation_1-rmse:606.758\n",
      "[300]\tvalidation_0-rmse:134.437\tvalidation_1-rmse:536.715\n",
      "Stopping. Best iteration:\n",
      "[274]\tvalidation_0-rmse:141.189\tvalidation_1-rmse:532.994\n",
      "\n",
      "0.40847847763405454\n",
      "valid mean: 395.0877990722656\n",
      "true  mean: 719.7307926829268\n",
      "test  mean: 285.6610107421875\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']\n",
    "def quantile_clip(group):\n",
    "    #group.plot()\n",
    "    group[group < group.quantile(.05)] = group.quantile(.05)\n",
    "    group[group > group.quantile(.95)] = group.quantile(.95)\n",
    "    #group.plot()\n",
    "    #plt.show()\n",
    "    return group\n",
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    data['salesVolume'] = data.groupby(['adcode', 'model'])['salesVolume'].transform(quantile_clip)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['province', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = province + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'xgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_xgb_areaSale_abnormal.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb+modelSale+abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 23.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 24\n",
      "train_idx: 13 20\n",
      "valid_idx: 21 21\n",
      "test_idx : 25 25\n",
      "[0]\tvalidation_0-rmse:757.617\tvalidation_1-rmse:931.125\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:718.08\tvalidation_1-rmse:891.171\n",
      "[200]\tvalidation_0-rmse:229.192\tvalidation_1-rmse:360.437\n",
      "[300]\tvalidation_0-rmse:119.722\tvalidation_1-rmse:230.494\n",
      "[400]\tvalidation_0-rmse:103.698\tvalidation_1-rmse:218.83\n",
      "[500]\tvalidation_0-rmse:94.7486\tvalidation_1-rmse:212.202\n",
      "[600]\tvalidation_0-rmse:89.3369\tvalidation_1-rmse:206.905\n",
      "[700]\tvalidation_0-rmse:82.5827\tvalidation_1-rmse:202.677\n",
      "[800]\tvalidation_0-rmse:77.5794\tvalidation_1-rmse:199.445\n",
      "[900]\tvalidation_0-rmse:74.1125\tvalidation_1-rmse:199.228\n",
      "[1000]\tvalidation_0-rmse:70.213\tvalidation_1-rmse:199.106\n",
      "Stopping. Best iteration:\n",
      "[915]\tvalidation_0-rmse:73.3155\tvalidation_1-rmse:198.483\n",
      "\n",
      "0.7721931151635194\n",
      "valid mean: 511.8463439941406\n",
      "true  mean: 556.6262195121955\n",
      "test  mean: 464.53106689453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 24.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 25\n",
      "train_idx: 13 21\n",
      "valid_idx: 22 22\n",
      "test_idx : 26 26\n",
      "[0]\tvalidation_0-rmse:778.807\tvalidation_1-rmse:898.617\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:739.264\tvalidation_1-rmse:859.893\n",
      "[200]\tvalidation_0-rmse:235.884\tvalidation_1-rmse:424.178\n",
      "[300]\tvalidation_0-rmse:120.441\tvalidation_1-rmse:368.182\n",
      "Stopping. Best iteration:\n",
      "[276]\tvalidation_0-rmse:127.413\tvalidation_1-rmse:367.475\n",
      "\n",
      "0.6007052563358208\n",
      "valid mean: 382.11505126953125\n",
      "true  mean: 531.6218680709541\n",
      "test  mean: 308.2127685546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 25.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 26\n",
      "train_idx: 13 22\n",
      "valid_idx: 23 23\n",
      "test_idx : 27 27\n",
      "[0]\tvalidation_0-rmse:791.604\tvalidation_1-rmse:956.125\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:752.093\tvalidation_1-rmse:916.34\n",
      "[200]\tvalidation_0-rmse:245.967\tvalidation_1-rmse:409.766\n",
      "[300]\tvalidation_0-rmse:131.308\tvalidation_1-rmse:282.392\n",
      "[400]\tvalidation_0-rmse:114.264\tvalidation_1-rmse:275.566\n",
      "[500]\tvalidation_0-rmse:103.827\tvalidation_1-rmse:270.372\n",
      "[600]\tvalidation_0-rmse:96.5414\tvalidation_1-rmse:269.005\n",
      "[700]\tvalidation_0-rmse:91.3058\tvalidation_1-rmse:267.183\n",
      "[800]\tvalidation_0-rmse:86.1202\tvalidation_1-rmse:265.523\n",
      "[900]\tvalidation_0-rmse:82.629\tvalidation_1-rmse:265.318\n",
      "[1000]\tvalidation_0-rmse:78.8261\tvalidation_1-rmse:264.432\n",
      "[1100]\tvalidation_0-rmse:74.9661\tvalidation_1-rmse:263.766\n",
      "Stopping. Best iteration:\n",
      "[1077]\tvalidation_0-rmse:75.6335\tvalidation_1-rmse:263.373\n",
      "\n",
      "0.7106738461252353\n",
      "valid mean: 472.6012268066406\n",
      "true  mean: 576.4874168514414\n",
      "test  mean: 357.1247253417969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 25.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "all_idx  : 13 27\n",
      "train_idx: 13 23\n",
      "valid_idx: 24 24\n",
      "test_idx : 28 28\n",
      "[0]\tvalidation_0-rmse:807.946\tvalidation_1-rmse:1189.55\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-rmse:768.363\tvalidation_1-rmse:1148.7\n",
      "[200]\tvalidation_0-rmse:252.286\tvalidation_1-rmse:617.703\n",
      "[300]\tvalidation_0-rmse:132.2\tvalidation_1-rmse:560.667\n",
      "Stopping. Best iteration:\n",
      "[243]\tvalidation_0-rmse:154.627\tvalidation_1-rmse:557.602\n",
      "\n",
      "0.39344372386673965\n",
      "valid mean: 384.47479248046875\n",
      "true  mean: 719.7307926829268\n",
      "test  mean: 350.4908142089844\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "#显示所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "#显示所有行\n",
    "pd.set_option('display.max_rows', None)\n",
    "#设置value的显示长度为100，默认为50\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "\n",
    "def get_stat_feature(df_):\n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "\n",
    "\n",
    "    #for col in tqdm(['label','popularity','area_sales_volume','pop_dist']):\n",
    "    for col in tqdm(['label', 'popularity', 'area_sales_volume']):\n",
    "        # shift\n",
    "        for i in [1,2,3,4,5,6,7,8,9]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])\n",
    "\n",
    "    return df, stat_feat\n",
    "\n",
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'.format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(\n",
    "            mse(raw[0], raw[1]) ** 0.5 / raw[2]\n",
    "        )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb'):\n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=5, random_state=2333,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              categorical_feature=cate_feat,\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000,\n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9,\n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse'\n",
    "                                )\n",
    "        model.fit(train_x, train_y,\n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)],\n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    return model\n",
    "\n",
    "def get_train_model(df_, m, m_type='lgb'):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分\n",
    "    st = 13\n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-5))\n",
    "    valid_idx = (df['mt'].between(m-4, m-4))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    print('all_idx  :',st ,m-1)\n",
    "    print('train_idx:',st ,m-5)\n",
    "    print('valid_idx:',m-4,m-4)\n",
    "    print('test_idx :',m  ,m  )\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['label']\n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type)\n",
    "    # offline\n",
    "    df['pred_label'] = model.predict(df[features])\n",
    "    best_score = score(df[valid_idx])\n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['label'])\n",
    "    df['forecastVolum'] = model.predict(df[features])\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    return sub,df[valid_idx]['pred_label']\n",
    "def quantile_clip(group):\n",
    "    #group.plot()\n",
    "    group[group < group.quantile(.05)] = group.quantile(.05)\n",
    "    group[group > group.quantile(.95)] = group.quantile(.95)\n",
    "    #group.plot()\n",
    "    #plt.show()\n",
    "    return group\n",
    "if __name__ == '__main__':\n",
    "    path = '../ccf_car/'\n",
    "    train_sales = pd.read_csv(path + 'train_sales_data.csv')\n",
    "    train_search = pd.read_csv(path + 'train_search_data.csv')\n",
    "    train_user = pd.read_csv(path + 'train_user_reply_data.csv')\n",
    "    evaluation_public = pd.read_csv(path + 'evaluation_public.csv')\n",
    "    submit_example = pd.read_csv(path + 'submit_example.csv')\n",
    "    data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "    data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "    data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "    data['salesVolume'] = data.groupby(['adcode', 'model'])['salesVolume'].transform(quantile_clip)\n",
    "    data['label'] = data['salesVolume']\n",
    "    data['id'] = data['id'].fillna(0).astype(int)\n",
    "    data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "    # LabelEncoder\n",
    "    for i in ['bodyType', 'model']:\n",
    "        data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "    data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']\n",
    "\n",
    "    area_sales = {}\n",
    "    for raw in data[['model', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        if area_sales.__contains__(key):\n",
    "            area_sales[key] += sales\n",
    "        else:\n",
    "            area_sales[key] = sales\n",
    "    new_column = []\n",
    "    new_column1 = []\n",
    "    for raw in data[['model', 'salesVolume','regMonth','regYear']].values:\n",
    "        province = raw[0]\n",
    "        sales = raw[1]\n",
    "        if pd.isna(sales):\n",
    "            new_column.append(None)\n",
    "            new_column1.append(None)\n",
    "            continue\n",
    "        regMonth = raw[2]\n",
    "        regYear = raw[3]\n",
    "        key = str(province) + \"_\" + str(regYear) + \"_\" + str(regMonth)\n",
    "        new_column.append(area_sales[key])\n",
    "        new_column1.append(sales/area_sales[key])\n",
    "    data['area_sales_volume'] = new_column\n",
    "\n",
    "    for month in [25, 26, 27, 28]:\n",
    "        m_type = 'xgb'\n",
    "\n",
    "        data_df, stat_feat = get_stat_feature(data)\n",
    "\n",
    "        num_feat = ['regYear'] + stat_feat\n",
    "        cate_feat = ['adcode', 'bodyType', 'model', 'regMonth']\n",
    "        if m_type == 'lgb':\n",
    "            for i in cate_feat:\n",
    "                data_df[i] = data_df[i].astype('category')\n",
    "        elif m_type == 'xgb':\n",
    "            lbl = LabelEncoder()\n",
    "            for i in tqdm(cate_feat):\n",
    "                data_df[i] = lbl.fit_transform(data_df[i].astype(str))\n",
    "\n",
    "        features = num_feat + cate_feat\n",
    "        print(len(features), len(set(features)))\n",
    "\n",
    "        #data_df.to_csv('middle_rst.csv',index=False)\n",
    "        #break\n",
    "        sub, val_pred = get_train_model(data_df, month, m_type)\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "        data.loc[(data.regMonth == (month - 24)) & (data.regYear == 2018), 'label'] = sub['forecastVolum'].values\n",
    "    sub = data.loc[(data.regMonth >= 1) & (data.regYear == 2018), ['id', 'salesVolume']]\n",
    "    sub.columns = ['id', 'forecastVolum']\n",
    "    sub[['id', 'forecastVolum']].round().astype(int).to_csv('../rst/myx_xgb_modelSale_abnormal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
