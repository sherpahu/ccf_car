{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import gc\n",
    "from tqdm import tqdm_notebook as tqdm # 如果使用.py文件的话可以把tqdm_notebook改成tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self):\n",
    "        self.unstack_data = {}\n",
    "        \n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.valid = None\n",
    "        self.train_target = None\n",
    "        self.valid_target = None\n",
    "        self.features = None\n",
    "        self.cat_feats = None\n",
    "        self.weight = None\n",
    "        \n",
    "        self.model = None\n",
    "    # 读取数据\n",
    "    def readData(self,path='../ccf_car/'):\n",
    "        \"\"\"\n",
    "        读取数据集\n",
    "        \"\"\"\n",
    "        train_sales = pd.read_csv(path+'train_sales_data.csv')\n",
    "        train_search = pd.read_csv(path+'train_search_data.csv')\n",
    "        test = pd.read_csv(path+'evaluation_public.csv')\n",
    "\n",
    "        train = pd.merge(train_sales, train_search, on=['province','adcode','model','regYear','regMonth'],how='left')\n",
    "\n",
    "        model_bodyType = train[['model','bodyType']].groupby(['model'],as_index=False).first()\n",
    "        test = pd.merge(test, model_bodyType, on='model', how='left')\n",
    "        return train, test\n",
    "    # 特征工程\n",
    "    def transStrFeats(self, df, l):\n",
    "        \"\"\"\n",
    "        字符特征转换\n",
    "        :param: l:要转码的特征列表\n",
    "        \"\"\"\n",
    "        for f in l:\n",
    "            map_dict = {i:j+1 for j,i in enumerate(df[f].unique())}\n",
    "            df[f] = df[f].map(map_dict)\n",
    "        return df\n",
    "    def getHistoryIncrease(self, dataset, step=1, wind=1, col='salesVolume'):\n",
    "        \"\"\"\n",
    "        计算历史涨幅\n",
    "        :param: step:月份跨度\n",
    "        :param: wind:计算涨幅的月份区间\n",
    "        :param: col:计算涨幅的目标列\n",
    "        例：step=1,wind=2,计算当月 前第1月 较 前第3月 的涨幅）\n",
    "        \"\"\"\n",
    "        if col not in self.unstack_data.keys():\n",
    "            res = []\n",
    "            bar = tqdm(dataset['province'].unique(), desc='history increase')\n",
    "            for i in bar:\n",
    "                for j in dataset['model'].unique():\n",
    "                    msk = (dataset['province']==i) & (dataset['model']==j)\n",
    "                    df = dataset[msk].copy().reset_index(drop=True)\n",
    "                    tmp=df['mt']\n",
    "                    df = df[['mt',col]].set_index('mt').T\n",
    "                    df['province'] = i\n",
    "                    df['model'] = j\n",
    "                    df['mt']=tmp.values\n",
    "                    #print(df.head())\n",
    "                    res.append(df)\n",
    "                    #print(res)\n",
    "            res = pd.concat(res).reset_index(drop=True)\n",
    "            self.unstack_data[col] = res.copy()\n",
    "            \n",
    "        res = self.unstack_data[col].copy()\n",
    "        print(res.head())\n",
    "        res_ = res.copy()\n",
    "        for i in range(step+wind+1,29):\n",
    "            res_[i] = (res[i-step] - res[i-(step+wind)]) / res[i-(step+wind)]\n",
    "        for i in range(1,step+wind+1):\n",
    "            res_[i]=np.NaN\n",
    "        res = res_.set_index(['province','model','mt']).stack().reset_index()\n",
    "        res.rename(columns={0:'{}_last{}_{}_increase'.format(col,step,wind)},inplace=True)\n",
    "        print(res.head())\n",
    "        print(len(res))\n",
    "        print(dataset.head())\n",
    "        print(len(dataset))\n",
    "        dataset = pd.merge(dataset, res, on=['province','model','mt'], how='left')\n",
    "\n",
    "        return dataset\n",
    "    \n",
    "    def genDataset(self, pred={}, month=1):\n",
    "        \"\"\"\n",
    "        生成做好特征工程的数据集\n",
    "        :param: pred: 测试集预测数据字典 {月份:预测结果}\n",
    "        :param: month: 当前预测的月份\n",
    "        \"\"\"\n",
    "        train, test = self.readData()\n",
    "        trainset = pd.concat([train, test]).reset_index(drop=True)\n",
    "        train_len = train.shape[0]\n",
    "\n",
    "        \n",
    "        trainset = self.transStrFeats(trainset, ['model'])\n",
    "        trainset['mt'] = (trainset['regYear'] - 2016) * 12 + trainset['regMonth']\n",
    "\n",
    "        if len(pred)>0:\n",
    "            for m in pred.keys():\n",
    "                test['salesVolume'] = pred[m]\n",
    "                msk = test['regMonth']==m\n",
    "                trainset['salesVolume'][trainset['mt']==(24+m)] = test['salesVolume'][msk].values\n",
    "        \n",
    "        #############################特征工程#############################\n",
    "        \n",
    "        df = trainset[['province','bodyType','model','mt','salesVolume']].copy()\n",
    "        for i in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "            history = df.copy()\n",
    "            history['mt'] += i\n",
    "            history.rename(columns={'salesVolume':'Label_{}m_ago'.format(i)},inplace=True)\n",
    "            trainset = pd.merge(trainset, history, on=['province','bodyType','model','mt'], how='left')\n",
    "        \n",
    "        df = trainset[['province','bodyType','model','mt','popularity']].copy()\n",
    "        for i in [4,5,6]:\n",
    "            history = df.copy()\n",
    "            history['mt'] += i\n",
    "            history.rename(columns={'popularity':'popularity_{}m_ago'.format(i)},inplace=True)\n",
    "            trainset = pd.merge(trainset, history, on=['province','bodyType','model','mt'], how='left')\n",
    "        \n",
    "        day_map = {1:31,2:28,3:31,4:30,5:31,6:30,7:31,8:31,9:30,10:31,11:30,12:31}\n",
    "        trainset['dayCount']=trainset['regMonth'].map(day_map)\n",
    "        trainset.loc[(trainset.regMonth==2)&(trainset.regYear==2016),'dayCount']=29\n",
    "        trainset['salesVolume']/=trainset['dayCount']\n",
    "        trainset['popularity']/=trainset['dayCount']\n",
    "        \n",
    "        base_step = month-1 if month-1>0 else 1\n",
    "        trainset = self.getHistoryIncrease(trainset, step=base_step)\n",
    "        trainset = self.getHistoryIncrease(trainset, step=base_step+1)\n",
    "        trainset = self.getHistoryIncrease(trainset, step=base_step+2)\n",
    "        trainset = self.getHistoryIncrease(trainset, step=base_step, wind=2)\n",
    "        trainset = self.getHistoryIncrease(trainset, step=base_step+1, wind=2)\n",
    "        trainset = self.getHistoryIncrease(trainset, step=base_step+2, wind=2)\n",
    "        trainset = self.getHistoryIncrease(trainset, step=base_step, wind=12)\n",
    "        \n",
    "        trainset = self.getHistoryIncrease(trainset, step=month, col='popularity')\n",
    "        trainset = self.getHistoryIncrease(trainset, step=month+1, col='popularity')\n",
    "        trainset = self.getHistoryIncrease(trainset, step=month+2, col='popularity')\n",
    "        trainset = self.getHistoryIncrease(trainset, step=month, wind=2, col='popularity')\n",
    "        trainset = self.getHistoryIncrease(trainset, step=month+1, wind=2, col='popularity')\n",
    "        trainset = self.getHistoryIncrease(trainset, step=month+2, wind=2, col='popularity')\n",
    "        \n",
    "        trainset['salesVolume']*=trainset['dayCount']\n",
    "        trainset['popularity']*=trainset['dayCount']\n",
    "        # 划分训练、验证集\n",
    "        train = trainset.iloc[:train_len]\n",
    "        test = trainset.iloc[train_len:]\n",
    "        valid_mask = (train['regYear']==2017) & (train['regMonth'].isin([9,10,11,12]))\n",
    "        valid = train[valid_mask].copy()\n",
    "        train = train[~valid_mask].copy()\n",
    "        \n",
    "        # 去掉无效特征\n",
    "        drop_l = ['adcode','forecastVolum','id']\n",
    "        train.drop(drop_l,axis=1,inplace=True)\n",
    "        test.drop(drop_l,axis=1,inplace=True)\n",
    "        valid.drop(drop_l,axis=1,inplace=True)\n",
    "\n",
    "        # 生成特征列表，训练标签\n",
    "        features = [_ for _ in train.columns if _ not in ['salesVolume']]\n",
    "        cat_feats = ['model', 'province', 'bodyType', 'regMonth']\n",
    "\n",
    "        label = 'salesVolume'\n",
    "        train_target = train[label].copy()\n",
    "        valid_target = valid[label].copy()\n",
    "\n",
    "        for f in cat_feats:\n",
    "            for df in [train, test, valid]:\n",
    "                df[f] = df[f].astype('category')\n",
    "\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.valid = valid\n",
    "        self.train_target = train_target\n",
    "        self.valid_target = valid_target\n",
    "        self.features = features\n",
    "        self.cat_feats = cat_feats\n",
    "    \n",
    "    # 模型训练\n",
    "    def getScore(self, df, oof):\n",
    "        score = 0\n",
    "        for f in df['model'].unique():\n",
    "            msk = df['model']==f\n",
    "            tmp = df[msk]\n",
    "            score += np.sqrt(mean_squared_error(tmp['salesVolume'],oof[msk]))/(tmp['salesVolume']).mean()\n",
    "        score = 1-score/df['model'].nunique()\n",
    "        return score\n",
    "    def lgb_train(self, param, data=None, verbose=500, num_round=20000):\n",
    "        if data is None:\n",
    "            train = self.train.copy()\n",
    "            test = self.test.copy()\n",
    "            valid = self.valid.copy()\n",
    "            train_target = self.train_target.copy()\n",
    "            valid_target = self.valid_target.copy()\n",
    "            features = self.features.copy()\n",
    "            cat_feats = self.cat_feats.copy()\n",
    "        else:\n",
    "            train = data['train'].copy()\n",
    "            test = data['test'].copy()\n",
    "            valid = data['valid'].copy()\n",
    "            train_target = data['train_target'].copy()\n",
    "            valid_target = data['valid_target'].copy()\n",
    "            features = data['features'].copy()\n",
    "            cat_feats = data['cat_features'].copy()\n",
    "\n",
    "\n",
    "        trn_data = lgb.Dataset(train[features], label=train_target.values)\n",
    "        val_data = lgb.Dataset(valid[features], label=valid_target.values)\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        model = lgb.train(\n",
    "            param, \n",
    "            trn_data, \n",
    "            num_round, \n",
    "            valid_sets = [trn_data, val_data], \n",
    "            verbose_eval=verbose, \n",
    "            early_stopping_rounds = 200,\n",
    "            categorical_feature=cat_feats,\n",
    "            )\n",
    "\n",
    "        feature_importance_df[\"Feature\"] = features\n",
    "        feature_importance_df[\"importance\"] = model.feature_importance()\n",
    "        oof = model.predict(valid[features], num_iteration=model.best_iteration)\n",
    "        print(\"CV score: {:<8.5f}\".format(self.getScore(valid, oof)))\n",
    "        \n",
    "        train_all = pd.concat([train, valid]).reset_index(drop=True)\n",
    "        for f in cat_feats:\n",
    "            train_all[f] = train_all[f].astype('category')\n",
    "        target_all = train_target.append(valid_target)\n",
    "        model = model.refit(train_all[features], target_all, categorical_feature=cat_feats)\n",
    "        pred = model.predict(test[features], num_iteration=model.best_iteration)\n",
    "        self.model = model\n",
    "        \n",
    "        gc.collect()\n",
    "        return oof, pred, feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ddb5fbcb27498e9abeab30b716bf6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='history increase', max=22), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      2\n",
      "2      3\n",
      "3      4\n",
      "4      5\n",
      "5      6\n",
      "6      7\n",
      "7      8\n",
      "8      9\n",
      "9     10\n",
      "10    11\n",
      "11    12\n",
      "12    13\n",
      "13    14\n",
      "14    15\n",
      "15    16\n",
      "16    17\n",
      "17    18\n",
      "18    19\n",
      "19    20\n",
      "20    21\n",
      "21    22\n",
      "22    23\n",
      "23    24\n",
      "24    25\n",
      "25    26\n",
      "26    27\n",
      "27    28\n",
      "Name: mt, dtype: int64\n",
      "1\n",
      "28\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-96d5abd3213b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mpred_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mbaseModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpred_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_importance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlgb_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mpred_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-ded9a27b1b05>\u001b[0m in \u001b[0;36mgenDataset\u001b[1;34m(self, pred, month)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[0mbase_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmonth\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetHistoryIncrease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m         \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetHistoryIncrease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_step\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mtrainset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetHistoryIncrease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_step\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-ded9a27b1b05>\u001b[0m in \u001b[0;36mgetHistoryIncrease\u001b[1;34m(self, dataset, step, wind, col)\u001b[0m\n\u001b[0;32m     59\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m                     \u001b[1;31m#print(df.head())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                     \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3470\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3471\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3472\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3474\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3548\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3549\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3550\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3733\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3734\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3735\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3736\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Length of values does not match length of index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.9,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    \"lambda_l1\": 0.1,\n",
    "    \"lambda_l2\": 1.2,\n",
    "    'min_data_in_leaf': 15,\n",
    "    \"metric\": 'mae',\n",
    "    'num_leaves': 31,\n",
    "    'num_threads': -1,\n",
    "    'objective': 'regression',\n",
    "    }\n",
    "\n",
    "\n",
    "baseModel = BaseModel()\n",
    "pred_dict = {}\n",
    "for i in [1,2,3,4]:\n",
    "    baseModel.genDataset(pred=pred_dict, month=i)\n",
    "    oof, pred, feat_importance = baseModel.lgb_train(params)\n",
    "    pred_dict[i] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
